"""
ã‚«ãƒ–ã‚¿ãƒ³é€£æºã‚µãƒ¼ãƒ“ã‚¹
æ±ºç®—çŸ­ä¿¡ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–ã¨æ¥­ç¸¾äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ãƒ»æ¯”è¼ƒ
"""

import logging
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import json
import re
from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote
from ..database.config import database
from ..database.tables import earnings_schedule, stock_master
from ..lib.logger import logger

class KabutanIntegrationService:
    """ã‚«ãƒ–ã‚¿ãƒ³é€£æºå°‚é–€ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        # ã‚«ãƒ–ã‚¿ãƒ³ã®åŸºæœ¬URL
        self.base_url = "https://kabutan.jp"
        self.api_endpoints = {
            'company_profile': '/stock/?code={stock_code}',
            'earnings_detail': '/stock/kessan?code={stock_code}',
            'forecast_data': '/stock/yosoku?code={stock_code}',
            'financial_summary': '/stock/finance?code={stock_code}',
            'news_disclosure': '/news/?b={stock_code}'
        }
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja-JP,ja;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self.cache = {}
        self.cache_ttl = 7200  # 2æ™‚é–“
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼ˆæ¯åˆ†æœ€å¤§5ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
        self.rate_limit = {
            'requests_per_minute': 5,
            'request_times': []
        }
    
    async def fetch_earnings_summary(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        æ±ºç®—çŸ­ä¿¡ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ åŒ–
        
        Args:
            stock_code: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
            
        Returns:
            æ§‹é€ åŒ–ã•ã‚ŒãŸæ±ºç®—ãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info(f"ğŸ“Š ã‚«ãƒ–ã‚¿ãƒ³æ±ºç®—ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {stock_code}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
            await self._check_rate_limit()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cache_key = f"earnings_{stock_code}"
            cached_data = self._get_cache(cache_key)
            if cached_data:
                logger.info(f"ğŸ“‹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—: {stock_code}")
                return cached_data
            
            # ã‚«ãƒ–ã‚¿ãƒ³ã‹ã‚‰æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            earnings_html = await self._fetch_from_kabutan(
                self.api_endpoints['earnings_detail'].format(stock_code=stock_code)
            )
            
            if not earnings_html:
                return self._get_sample_earnings_data(stock_code)
            
            # HTMLã‚’è§£æã—ã¦æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            earnings_data = self._parse_earnings_html(earnings_html, stock_code)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–
            structured_data = self._structure_earnings_summary(earnings_data, stock_code)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self._set_cache(cache_key, structured_data)
            
            logger.info(f"âœ… æ±ºç®—ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {stock_code}")
            return structured_data
            
        except Exception as e:
            logger.error(f"âŒ ã‚«ãƒ–ã‚¿ãƒ³æ±ºç®—ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ ({stock_code}): {str(e)}")
            return self._get_sample_earnings_data(stock_code)
    
    async def _fetch_from_kabutan(self, endpoint: str) -> Optional[str]:
        """ã‚«ãƒ–ã‚¿ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            url = f"{self.base_url}{endpoint}"
            
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(headers=self.headers, timeout=timeout) as session:
                try:
                    async with session.get(url) as response:
                        if response.status == 200:
                            return await response.text()
                        else:
                            logger.warning(f"âš ï¸ ã‚«ãƒ–ã‚¿ãƒ³APIå¿œç­”ã‚¨ãƒ©ãƒ¼: {response.status}")
                            return None
                            
                except aiohttp.ClientError as e:
                    logger.warning(f"âš ï¸ ã‚«ãƒ–ã‚¿ãƒ³æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ ã‚«ãƒ–ã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def _parse_earnings_html(self, html_content: str, stock_code: str) -> Dict[str, Any]:
        """æ±ºç®—HTMLãƒšãƒ¼ã‚¸ã‚’è§£æ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            earnings_data = {
                'stock_code': stock_code,
                'quarters': [],
                'annual_results': [],
                'forecasts': []
            }
            
            # å››åŠæœŸæ±ºç®—ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ¤œç´¢
            quarterly_table = soup.find('table', {'class': 'stock_table'})
            if not quarterly_table:
                quarterly_table = soup.find('table', id=re.compile(r'quarterly|earnings'))
            
            if quarterly_table:
                earnings_data['quarters'] = self._parse_quarterly_table(quarterly_table)
            
            # é€šæœŸæ±ºç®—ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ¤œç´¢
            annual_table = soup.find('table', {'class': 'annual_table'})
            if not annual_table:
                annual_tables = soup.find_all('table')
                for table in annual_tables:
                    if 'é€šæœŸ' in table.get_text():
                        annual_table = table
                        break
            
            if annual_table:
                earnings_data['annual_results'] = self._parse_annual_table(annual_table)
            
            # æ¥­ç¸¾äºˆæƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã®æ¤œç´¢
            forecast_table = soup.find('table', {'class': 'forecast_table'})
            if forecast_table:
                earnings_data['forecasts'] = self._parse_forecast_table(forecast_table)
            
            return earnings_data
            
        except Exception as e:
            logger.error(f"âŒ æ±ºç®—HTMLè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'stock_code': stock_code, 'quarters': [], 'annual_results': [], 'forecasts': []}
    
    def _parse_quarterly_table(self, table) -> List[Dict[str, Any]]:
        """å››åŠæœŸæ±ºç®—ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è§£æ"""
        try:
            quarters = []
            rows = table.find_all('tr')
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‹ã‚‰æœŸé–“æƒ…å ±ã‚’å–å¾—
            header_row = rows[0]
            periods = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])[1:]]
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ
            data_rows = rows[1:]
            financial_data = {}
            
            for row in data_rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) > 1:
                    label = cells[0].get_text(strip=True)
                    values = [cell.get_text(strip=True) for cell in cells[1:]]
                    financial_data[label] = values
            
            # æœŸé–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–
            for i, period in enumerate(periods):
                if i < len(financial_data.get('å£²ä¸Šé«˜', [])):
                    quarter_data = {
                        'period': period,
                        'revenue': self._parse_financial_value(financial_data.get('å£²ä¸Šé«˜', [])[i] if i < len(financial_data.get('å£²ä¸Šé«˜', [])) else ''),
                        'operating_income': self._parse_financial_value(financial_data.get('å–¶æ¥­åˆ©ç›Š', [])[i] if i < len(financial_data.get('å–¶æ¥­åˆ©ç›Š', [])) else ''),
                        'ordinary_income': self._parse_financial_value(financial_data.get('çµŒå¸¸åˆ©ç›Š', [])[i] if i < len(financial_data.get('çµŒå¸¸åˆ©ç›Š', [])) else ''),
                        'net_income': self._parse_financial_value(financial_data.get('ç´”åˆ©ç›Š', [])[i] if i < len(financial_data.get('ç´”åˆ©ç›Š', [])) else ''),
                        'quarter_type': self._determine_quarter_type(period)
                    }
                    quarters.append(quarter_data)
            
            return quarters
            
        except Exception as e:
            logger.error(f"âŒ å››åŠæœŸãƒ†ãƒ¼ãƒ–ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _parse_annual_table(self, table) -> List[Dict[str, Any]]:
        """é€šæœŸæ±ºç®—ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è§£æ"""
        try:
            annual_results = []
            rows = table.find_all('tr')
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‹ã‚‰å¹´åº¦æƒ…å ±ã‚’å–å¾—
            header_row = rows[0]
            years = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])[1:]]
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è§£æ
            data_rows = rows[1:]
            financial_data = {}
            
            for row in data_rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) > 1:
                    label = cells[0].get_text(strip=True)
                    values = [cell.get_text(strip=True) for cell in cells[1:]]
                    financial_data[label] = values
            
            # å¹´åº¦ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–
            for i, year in enumerate(years):
                if i < len(financial_data.get('å£²ä¸Šé«˜', [])):
                    annual_data = {
                        'fiscal_year': self._extract_fiscal_year(year),
                        'revenue': self._parse_financial_value(financial_data.get('å£²ä¸Šé«˜', [])[i] if i < len(financial_data.get('å£²ä¸Šé«˜', [])) else ''),
                        'operating_income': self._parse_financial_value(financial_data.get('å–¶æ¥­åˆ©ç›Š', [])[i] if i < len(financial_data.get('å–¶æ¥­åˆ©ç›Š', [])) else ''),
                        'ordinary_income': self._parse_financial_value(financial_data.get('çµŒå¸¸åˆ©ç›Š', [])[i] if i < len(financial_data.get('çµŒå¸¸åˆ©ç›Š', [])) else ''),
                        'net_income': self._parse_financial_value(financial_data.get('ç´”åˆ©ç›Š', [])[i] if i < len(financial_data.get('ç´”åˆ©ç›Š', [])) else ''),
                        'eps': self._parse_financial_value(financial_data.get('EPS', [])[i] if i < len(financial_data.get('EPS', [])) else ''),
                        'dividend': self._parse_financial_value(financial_data.get('é…å½“', [])[i] if i < len(financial_data.get('é…å½“', [])) else '')
                    }
                    annual_results.append(annual_data)
            
            return annual_results
            
        except Exception as e:
            logger.error(f"âŒ é€šæœŸãƒ†ãƒ¼ãƒ–ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _parse_forecast_table(self, table) -> List[Dict[str, Any]]:
        """æ¥­ç¸¾äºˆæƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è§£æ"""
        try:
            forecasts = []
            rows = table.find_all('tr')
            
            # äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã®è§£æ
            for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 6:
                    forecast = {
                        'forecast_period': cells[0].get_text(strip=True),
                        'revenue_forecast': self._parse_financial_value(cells[1].get_text(strip=True)),
                        'operating_income_forecast': self._parse_financial_value(cells[2].get_text(strip=True)),
                        'ordinary_income_forecast': self._parse_financial_value(cells[3].get_text(strip=True)),
                        'net_income_forecast': self._parse_financial_value(cells[4].get_text(strip=True)),
                        'eps_forecast': self._parse_financial_value(cells[5].get_text(strip=True)),
                        'forecast_date': datetime.now()
                    }
                    forecasts.append(forecast)
            
            return forecasts
            
        except Exception as e:
            logger.error(f"âŒ æ¥­ç¸¾äºˆæƒ³ãƒ†ãƒ¼ãƒ–ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def _parse_financial_value(self, value_str: str) -> Optional[float]:
        """è²¡å‹™æ•°å€¤æ–‡å­—åˆ—ã‚’æ•°å€¤ã«å¤‰æ›"""
        try:
            if not value_str or value_str.strip() in ['--', '-', '']:
                return None
            
            # æ•°å­—ã¨ãƒ”ãƒªã‚ªãƒ‰ã€ãƒã‚¤ãƒŠã‚¹è¨˜å·ä»¥å¤–ã‚’é™¤å»
            cleaned = re.sub(r'[^\d.-]', '', value_str)
            
            if not cleaned:
                return None
            
            # å˜ä½ã‚’åˆ¤å®šï¼ˆç™¾ä¸‡å††ã€å„„å††ãªã©ï¼‰
            multiplier = 1
            if 'å„„' in value_str:
                multiplier = 100_000_000
            elif 'ç™¾ä¸‡' in value_str or 'ç™¾ä¸‡å††' in value_str:
                multiplier = 1_000_000
            elif 'åƒ' in value_str or 'åƒå††' in value_str:
                multiplier = 1_000
            
            return float(cleaned) * multiplier
            
        except (ValueError, TypeError):
            return None
    
    def _determine_quarter_type(self, period_str: str) -> str:
        """æœŸé–“æ–‡å­—åˆ—ã‹ã‚‰å››åŠæœŸã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        if '1Q' in period_str or 'ç¬¬1' in period_str:
            return 'Q1'
        elif '2Q' in period_str or 'ç¬¬2' in period_str:
            return 'Q2'
        elif '3Q' in period_str or 'ç¬¬3' in period_str:
            return 'Q3'
        elif '4Q' in period_str or 'ç¬¬4' in period_str or 'é€šæœŸ' in period_str:
            return 'Q4'
        else:
            return 'FY'
    
    def _extract_fiscal_year(self, year_str: str) -> int:
        """å¹´åº¦æ–‡å­—åˆ—ã‹ã‚‰å¹´åº¦ã‚’æŠ½å‡º"""
        try:
            # 4æ¡ã®æ•°å­—ã‚’æ¤œç´¢
            match = re.search(r'\d{4}', year_str)
            return int(match.group()) if match else datetime.now().year
        except (ValueError, AttributeError):
            return datetime.now().year
    
    def _structure_earnings_summary(self, earnings_data: Dict[str, Any], stock_code: str) -> Dict[str, Any]:
        """æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–"""
        try:
            # æœ€æ–°ã®é€šæœŸçµæœã‚’å–å¾—
            latest_annual = earnings_data['annual_results'][0] if earnings_data['annual_results'] else {}
            previous_annual = earnings_data['annual_results'][1] if len(earnings_data['annual_results']) > 1 else {}
            
            # é»’å­—è»¢æ›ã®åˆ¤å®š
            is_black_ink_conversion = False
            if (previous_annual.get('ordinary_income', 0) or 0) <= 0 and (latest_annual.get('ordinary_income', 0) or 0) > 0:
                is_black_ink_conversion = True
            
            # æˆé•·ç‡è¨ˆç®—
            revenue_growth = self._calculate_growth_rate(
                latest_annual.get('revenue'), 
                previous_annual.get('revenue')
            )
            
            profit_growth = self._calculate_growth_rate(
                latest_annual.get('ordinary_income'),
                previous_annual.get('ordinary_income')
            )
            
            # æœ€æ–°å››åŠæœŸãƒ‡ãƒ¼ã‚¿
            latest_quarter = earnings_data['quarters'][0] if earnings_data['quarters'] else {}
            
            # æ¥­ç¸¾äºˆæƒ³ãƒ‡ãƒ¼ã‚¿
            current_forecast = earnings_data['forecasts'][0] if earnings_data['forecasts'] else {}
            
            structured_summary = {
                'stock_code': stock_code,
                'analysis_date': datetime.now(),
                'data_source': 'kabutan',
                
                # æœ€æ–°é€šæœŸå®Ÿç¸¾
                'latest_annual': {
                    'fiscal_year': latest_annual.get('fiscal_year', datetime.now().year),
                    'revenue': latest_annual.get('revenue'),
                    'operating_income': latest_annual.get('operating_income'),
                    'ordinary_income': latest_annual.get('ordinary_income'),
                    'net_income': latest_annual.get('net_income'),
                    'eps': latest_annual.get('eps'),
                    'dividend': latest_annual.get('dividend')
                },
                
                # å‰å¹´åº¦å®Ÿç¸¾
                'previous_annual': {
                    'fiscal_year': previous_annual.get('fiscal_year', datetime.now().year - 1),
                    'revenue': previous_annual.get('revenue'),
                    'operating_income': previous_annual.get('operating_income'),
                    'ordinary_income': previous_annual.get('ordinary_income'),
                    'net_income': previous_annual.get('net_income')
                },
                
                # æˆé•·åˆ†æ
                'growth_analysis': {
                    'is_black_ink_conversion': is_black_ink_conversion,
                    'revenue_growth_rate': revenue_growth,
                    'profit_growth_rate': profit_growth,
                    'profit_trend': self._analyze_profit_trend(earnings_data['annual_results'])
                },
                
                # æœ€æ–°å››åŠæœŸ
                'latest_quarter': latest_quarter,
                
                # æ¥­ç¸¾äºˆæƒ³
                'current_forecast': current_forecast,
                
                # ãƒªã‚¹ã‚¯è©•ä¾¡
                'risk_assessment': self._assess_financial_risk(earnings_data),
                
                # ç”Ÿãƒ‡ãƒ¼ã‚¿
                'raw_data': earnings_data,
                'last_updated': datetime.now()
            }
            
            return structured_summary
            
        except Exception as e:
            logger.error(f"âŒ æ±ºç®—ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._get_sample_earnings_data(stock_code)
    
    def _calculate_growth_rate(self, current: Optional[float], previous: Optional[float]) -> Optional[float]:
        """æˆé•·ç‡ã‚’è¨ˆç®—"""
        try:
            if current is None or previous is None or previous == 0:
                return None
            
            growth_rate = ((current - previous) / abs(previous)) * 100
            return round(growth_rate, 2)
            
        except (TypeError, ZeroDivisionError):
            return None
    
    def _analyze_profit_trend(self, annual_results: List[Dict[str, Any]]) -> str:
        """åˆ©ç›Šãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ"""
        try:
            if len(annual_results) < 2:
                return 'insufficient_data'
            
            # éå»3å¹´ã®çµŒå¸¸åˆ©ç›Šã‚’ãƒã‚§ãƒƒã‚¯
            profits = []
            for result in annual_results[:3]:
                profit = result.get('ordinary_income')
                if profit is not None:
                    profits.append(profit)
            
            if len(profits) < 2:
                return 'insufficient_data'
            
            # é€£ç¶šæˆé•·åˆ¤å®š
            is_growing = True
            for i in range(len(profits) - 1):
                if profits[i] <= profits[i + 1]:
                    is_growing = False
                    break
            
            if is_growing:
                return 'consecutive_growth'
            elif profits[0] > 0 and any(p <= 0 for p in profits[1:]):
                return 'recovery'
            elif profits[0] <= 0 and profits[1] <= 0:
                return 'persistent_loss'
            else:
                return 'volatile'
                
        except Exception as e:
            return 'analysis_error'
    
    def _assess_financial_risk(self, earnings_data: Dict[str, Any]) -> Dict[str, Any]:
        """è²¡å‹™ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡"""
        try:
            annual_results = earnings_data['annual_results']
            if not annual_results:
                return {'risk_level': 'unknown', 'factors': []}
            
            latest = annual_results[0]
            risk_factors = []
            risk_score = 0
            
            # èµ¤å­—ãƒã‚§ãƒƒã‚¯
            if (latest.get('ordinary_income') or 0) <= 0:
                risk_factors.append('çµŒå¸¸èµ¤å­—')
                risk_score += 30
            
            # å£²ä¸Šæ¸›å°‘ãƒã‚§ãƒƒã‚¯
            if len(annual_results) >= 2:
                revenue_growth = self._calculate_growth_rate(
                    latest.get('revenue'),
                    annual_results[1].get('revenue')
                )
                if revenue_growth and revenue_growth < -10:
                    risk_factors.append('å£²ä¸Šå¤§å¹…æ¸›å°‘')
                    risk_score += 20
            
            # EPSæ‚ªåŒ–ãƒã‚§ãƒƒã‚¯
            if (latest.get('eps') or 0) < 0:
                risk_factors.append('1æ ªå½“ãŸã‚Šåˆ©ç›Šãƒã‚¤ãƒŠã‚¹')
                risk_score += 15
            
            # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
            if risk_score >= 50:
                risk_level = 'high'
            elif risk_score >= 25:
                risk_level = 'medium'
            else:
                risk_level = 'low'
            
            return {
                'risk_level': risk_level,
                'risk_score': risk_score,
                'risk_factors': risk_factors,
                'assessment_date': datetime.now()
            }
            
        except Exception as e:
            return {
                'risk_level': 'unknown',
                'risk_score': 0,
                'risk_factors': ['è©•ä¾¡ã‚¨ãƒ©ãƒ¼'],
                'error': str(e)
            }
    
    async def fetch_company_profile(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—"""
        try:
            logger.info(f"ğŸ¢ ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—é–‹å§‹: {stock_code}")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
            await self._check_rate_limit()
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            cache_key = f"profile_{stock_code}"
            cached_data = self._get_cache(cache_key)
            if cached_data:
                return cached_data
            
            # ã‚«ãƒ–ã‚¿ãƒ³ã‹ã‚‰ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’å–å¾—
            profile_html = await self._fetch_from_kabutan(
                self.api_endpoints['company_profile'].format(stock_code=stock_code)
            )
            
            if not profile_html:
                return None
            
            # HTMLã‚’è§£æ
            profile_data = self._parse_company_profile(profile_html, stock_code)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self._set_cache(cache_key, profile_data)
            
            logger.info(f"âœ… ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—å®Œäº†: {stock_code}")
            return profile_data
            
        except Exception as e:
            logger.error(f"âŒ ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼ ({stock_code}): {str(e)}")
            return None
    
    def _parse_company_profile(self, html_content: str, stock_code: str) -> Dict[str, Any]:
        """ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«HTMLã‚’è§£æ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ä¼æ¥­æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¤œç´¢
            profile_table = soup.find('table', {'class': 'company_info'})
            if not profile_table:
                profile_table = soup.find('table', id=re.compile(r'profile|company'))
            
            profile_data = {
                'stock_code': stock_code,
                'company_name': '',
                'market': '',
                'sector': '',
                'business_description': '',
                'listing_date': None,
                'market_cap': None,
                'data_source': 'kabutan',
                'extracted_at': datetime.now()
            }
            
            if profile_table:
                rows = profile_table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        label = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        
                        if 'ä¼šç¤¾å' in label or 'éŠ˜æŸ„å' in label:
                            profile_data['company_name'] = value
                        elif 'å¸‚å ´' in label:
                            profile_data['market'] = value
                        elif 'æ¥­ç¨®' in label or 'ã‚»ã‚¯ã‚¿ãƒ¼' in label:
                            profile_data['sector'] = value
                        elif 'æ™‚ä¾¡ç·é¡' in label:
                            profile_data['market_cap'] = self._parse_financial_value(value)
                        elif 'ä¸Šå ´æ—¥' in label:
                            profile_data['listing_date'] = self._parse_date(value)
            
            # äº‹æ¥­å†…å®¹ã®æŠ½å‡º
            business_section = soup.find('div', {'class': 'business_description'})
            if business_section:
                profile_data['business_description'] = business_section.get_text(strip=True)
            
            return profile_data
            
        except Exception as e:
            logger.error(f"âŒ ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'stock_code': stock_code, 'data_source': 'kabutan', 'extracted_at': datetime.now()}
    
    def _parse_date(self, date_str: str) -> Optional[datetime]:
        """æ—¥ä»˜æ–‡å­—åˆ—ã‚’è§£æ"""
        try:
            # è¤‡æ•°ã®æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©¦è¡Œ
            date_formats = ['%Yå¹´%mæœˆ%dæ—¥', '%Y/%m/%d', '%Y-%m-%d']
            
            for fmt in date_formats:
                try:
                    return datetime.strptime(date_str.strip(), fmt)
                except ValueError:
                    continue
            
            return None
            
        except Exception:
            return None
    
    def _get_sample_earnings_data(self, stock_code: str) -> Dict[str, Any]:
        """ã‚µãƒ³ãƒ—ãƒ«æ±ºç®—ãƒ‡ãƒ¼ã‚¿"""
        return {
            'stock_code': stock_code,
            'analysis_date': datetime.now(),
            'data_source': 'kabutan_sample',
            'latest_annual': {
                'fiscal_year': 2024,
                'revenue': 1000000000,
                'operating_income': 50000000,
                'ordinary_income': 45000000,
                'net_income': 30000000,
                'eps': 100.0,
                'dividend': 20.0
            },
            'previous_annual': {
                'fiscal_year': 2023,
                'revenue': 950000000,
                'ordinary_income': -10000000,
                'net_income': -15000000
            },
            'growth_analysis': {
                'is_black_ink_conversion': True,
                'revenue_growth_rate': 5.26,
                'profit_growth_rate': None,
                'profit_trend': 'recovery'
            },
            'risk_assessment': {
                'risk_level': 'low',
                'risk_score': 10,
                'risk_factors': []
            },
            'last_updated': datetime.now()
        }
    
    async def _check_rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯"""
        now = datetime.now().timestamp()
        # 1åˆ†å‰ã‚ˆã‚Šå¤ã„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‰Šé™¤
        self.rate_limit['request_times'] = [
            t for t in self.rate_limit['request_times'] 
            if now - t < 60
        ]
        
        if len(self.rate_limit['request_times']) >= self.rate_limit['requests_per_minute']:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«å¼•ã£ã‹ã‹ã£ãŸå ´åˆã¯å°‘ã—å¾…æ©Ÿ
            await asyncio.sleep(12)  # 1åˆ†/5ãƒªã‚¯ã‚¨ã‚¹ãƒˆ = 12ç§’é–“éš”
        
        self.rate_limit['request_times'].append(now)
    
    def _get_cache(self, key: str) -> Optional[Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        if key in self.cache:
            data, timestamp = self.cache[key]
            if datetime.now().timestamp() - timestamp < self.cache_ttl:
                return data
            else:
                del self.cache[key]
        return None
    
    def _set_cache(self, key: str, data: Any):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        self.cache[key] = (data, datetime.now().timestamp())
    
    async def save_earnings_to_database(self, earnings_summary: Dict[str, Any]) -> bool:
        """æ±ºç®—ã‚µãƒãƒªãƒ¼ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        try:
            stock_code = earnings_summary['stock_code']
            latest_annual = earnings_summary['latest_annual']
            
            # earnings_scheduleãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
            earnings_id = f"earnings-{stock_code}-{latest_annual['fiscal_year']}-FY"
            
            db_data = {
                'id': earnings_id,
                'stock_code': stock_code,
                'stock_name': earnings_summary.get('company_name', f'éŠ˜æŸ„{stock_code}'),
                'fiscal_year': latest_annual['fiscal_year'],
                'fiscal_quarter': 'FY',
                'revenue_actual': latest_annual.get('revenue'),
                'profit_actual': latest_annual.get('ordinary_income'),
                'profit_previous': earnings_summary['previous_annual'].get('ordinary_income'),
                'is_black_ink_conversion': earnings_summary['growth_analysis']['is_black_ink_conversion'],
                'earnings_status': 'announced',
                'data_source': 'kabutan',
                'last_updated_from_source': earnings_summary['last_updated'],
                'is_target_for_logic_b': earnings_summary['growth_analysis']['is_black_ink_conversion'],
                'metadata_info': {
                    'kabutan_summary': earnings_summary,
                    'risk_assessment': earnings_summary['risk_assessment']
                }
            }
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            existing = await database.fetch_one(
                earnings_schedule.select().where(earnings_schedule.c.id == earnings_id)
            )
            
            if existing:
                await database.execute(
                    earnings_schedule.update().where(
                        earnings_schedule.c.id == earnings_id
                    ).values(**db_data)
                )
            else:
                await database.execute(
                    earnings_schedule.insert().values(**db_data)
                )
            
            logger.info(f"âœ… æ±ºç®—ã‚µãƒãƒªãƒ¼DBä¿å­˜å®Œäº†: {stock_code}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ±ºç®—ã‚µãƒãƒªãƒ¼DBä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    async def get_service_status(self) -> Dict[str, Any]:
        """ã‚«ãƒ–ã‚¿ãƒ³é€£æºã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹å–å¾—"""
        return {
            'service_name': 'ã‚«ãƒ–ã‚¿ãƒ³é€£æºã‚µãƒ¼ãƒ“ã‚¹',
            'status': 'active',
            'cache_entries': len(self.cache),
            'rate_limit_status': {
                'requests_in_last_minute': len(self.rate_limit['request_times']),
                'max_requests_per_minute': self.rate_limit['requests_per_minute']
            },
            'endpoints': self.api_endpoints,
            'last_updated': datetime.now().isoformat()
        }

# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
async def test_kabutan_integration():
    """ã‚«ãƒ–ã‚¿ãƒ³é€£æºã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    service = KabutanIntegrationService()
    
    logger.info("=== ã‚«ãƒ–ã‚¿ãƒ³é€£æºãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    test_codes = ["7203", "6758", "9984"]
    
    for stock_code in test_codes:
        # æ±ºç®—ã‚µãƒãƒªãƒ¼å–å¾—ãƒ†ã‚¹ãƒˆ
        earnings_summary = await service.fetch_earnings_summary(stock_code)
        if earnings_summary:
            logger.info(f"{stock_code} æ±ºç®—ã‚µãƒãƒªãƒ¼å–å¾—æˆåŠŸ")
            logger.info(f"  é»’å­—è»¢æ›: {earnings_summary['growth_analysis']['is_black_ink_conversion']}")
            logger.info(f"  å£²ä¸Šæˆé•·ç‡: {earnings_summary['growth_analysis']['revenue_growth_rate']}%")
        
        # ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—ãƒ†ã‚¹ãƒˆ
        profile = await service.fetch_company_profile(stock_code)
        if profile:
            logger.info(f"{stock_code} ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«å–å¾—æˆåŠŸ: {profile['company_name']}")
    
    # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
    status = await service.get_service_status()
    logger.info(f"ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹: {status['status']}")

if __name__ == "__main__":
    asyncio.run(test_kabutan_integration())