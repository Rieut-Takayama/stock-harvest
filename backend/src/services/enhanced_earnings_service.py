"""
å¼·åŒ–ç‰ˆæ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹
å››åŠæœŸåˆ¥æ±ºç®—ç®¡ç†ãƒ»é»’å­—è»¢æ›æ¤œå‡ºãƒ»IRãƒãƒ³ã‚¯/ã‚«ãƒ–ã‚¿ãƒ³çµ±åˆ
"""

import logging
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Any, Tuple
from sqlalchemy import and_, or_, desc, asc
from ..database.config import database
from ..database.tables import earnings_schedule, stock_master, listing_dates
from .irbank_integration_service import IRBankIntegrationService
from .kabutan_integration_service import KabutanIntegrationService
from .earnings_analysis_service import EarningsAnalysisService
from ..lib.logger import logger

class EnhancedEarningsService:
    """å¼·åŒ–ç‰ˆæ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†å°‚é–€ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        # å¤–éƒ¨é€£æºã‚µãƒ¼ãƒ“ã‚¹
        self.irbank_service = IRBankIntegrationService()
        self.kabutan_service = KabutanIntegrationService()
        self.earnings_analysis = EarningsAnalysisService()
        
        # è¨­å®š
        self.config = {
            'black_ink_threshold_months': 12,  # é»’å­—è»¢æ›åˆ¤å®šæœŸé–“
            'forecast_accuracy_threshold': 0.15,  # äºˆæƒ³ç²¾åº¦é–¾å€¤ï¼ˆ15%ï¼‰
            'priority_sectors': ['ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼', 'åŒ»è–¬å“', 'ãƒã‚¤ã‚ª'],  # å„ªå…ˆæ¥­ç¨®
            'max_historical_years': 5,  # éå»ãƒ‡ãƒ¼ã‚¿ä¿æŒå¹´æ•°
            'auto_update_earnings': True  # è‡ªå‹•æ±ºç®—ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        }
    
    async def get_comprehensive_earnings_calendar(self, 
                                                 start_date: Optional[str] = None, 
                                                 end_date: Optional[str] = None,
                                                 include_forecasts: bool = True) -> Dict[str, Any]:
        """
        åŒ…æ‹¬çš„ãªæ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚’å–å¾—
        
        Args:
            start_date: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
            end_date: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰
            include_forecasts: æ¥­ç¸¾äºˆæƒ³ã‚’å«ã‚ã‚‹ã‹
            
        Returns:
            æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿
        """
        try:
            logger.info("ğŸ“… åŒ…æ‹¬çš„æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å–å¾—é–‹å§‹")
            
            # æ—¥ä»˜ç¯„å›²ã®è¨­å®š
            if not start_date:
                start_date = datetime.now().strftime('%Y-%m-%d')
            if not end_date:
                end_date = (datetime.now() + timedelta(days=90)).strftime('%Y-%m-%d')
            
            # åŸºæœ¬ã®æ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—
            earnings_query = """
                SELECT 
                    e.*,
                    l.market,
                    l.sector,
                    l.years_since_listing,
                    l.is_target as is_listing_target
                FROM earnings_schedule e
                LEFT JOIN listing_dates l ON e.stock_code = l.stock_code
                WHERE e.scheduled_date BETWEEN :start_date AND :end_date
                ORDER BY e.scheduled_date ASC, e.announcement_time ASC
            """
            
            earnings_results = await database.fetch_all(
                earnings_query, 
                values={"start_date": start_date, "end_date": end_date}
            )
            
            # æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–
            calendar_data = {
                'period': {
                    'start_date': start_date,
                    'end_date': end_date,
                    'total_days': (datetime.strptime(end_date, '%Y-%m-%d') - 
                                 datetime.strptime(start_date, '%Y-%m-%d')).days
                },
                'summary': {
                    'total_earnings': len(earnings_results),
                    'black_ink_candidates': 0,
                    'priority_sector_count': 0,
                    'listing_target_count': 0
                },
                'by_date': {},
                'by_quarter': {'Q1': [], 'Q2': [], 'Q3': [], 'Q4': [], 'FY': []},
                'by_sector': {},
                'black_ink_candidates': [],
                'high_priority_earnings': []
            }
            
            # å„æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
            for row in earnings_results:
                earnings_item = await self._enrich_earnings_data(dict(row), include_forecasts)
                
                # æ—¥ä»˜åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                sched_date = earnings_item['scheduled_date'].strftime('%Y-%m-%d')
                if sched_date not in calendar_data['by_date']:
                    calendar_data['by_date'][sched_date] = []
                calendar_data['by_date'][sched_date].append(earnings_item)
                
                # å››åŠæœŸåˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                quarter = earnings_item['fiscal_quarter']
                if quarter in calendar_data['by_quarter']:
                    calendar_data['by_quarter'][quarter].append(earnings_item)
                
                # æ¥­ç¨®åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                sector = earnings_item.get('sector', 'æœªåˆ†é¡')
                if sector not in calendar_data['by_sector']:
                    calendar_data['by_sector'][sector] = []
                calendar_data['by_sector'][sector].append(earnings_item)
                
                # é»’å­—è»¢æ›å€™è£œ
                if earnings_item.get('is_black_ink_conversion'):
                    calendar_data['black_ink_candidates'].append(earnings_item)
                    calendar_data['summary']['black_ink_candidates'] += 1
                
                # å„ªå…ˆã‚»ã‚¯ã‚¿ãƒ¼
                if sector in self.config['priority_sectors']:
                    calendar_data['summary']['priority_sector_count'] += 1
                
                # ä¸Šå ´å¯¾è±¡
                if earnings_item.get('is_listing_target'):
                    calendar_data['summary']['listing_target_count'] += 1
                
                # é«˜å„ªå…ˆåº¦æ±ºç®—
                priority_score = self._calculate_earnings_priority(earnings_item)
                if priority_score >= 70:
                    calendar_data['high_priority_earnings'].append({
                        **earnings_item,
                        'priority_score': priority_score
                    })
            
            # é«˜å„ªå…ˆåº¦æ±ºç®—ã‚’å„ªå…ˆåº¦é †ã§ã‚½ãƒ¼ãƒˆ
            calendar_data['high_priority_earnings'].sort(
                key=lambda x: x['priority_score'], reverse=True
            )
            
            logger.info(f"âœ… æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å–å¾—å®Œäº†: {len(earnings_results)} ä»¶")
            return calendar_data
            
        except Exception as e:
            logger.error(f"âŒ æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    async def _enrich_earnings_data(self, earnings_base: Dict[str, Any], include_forecasts: bool = True) -> Dict[str, Any]:
        """æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ æƒ…å ±ã§å¼·åŒ–"""
        try:
            stock_code = earnings_base['stock_code']
            
            # åŸºæœ¬æƒ…å ±ã®æ§‹é€ åŒ–
            enriched = {
                **earnings_base,
                'days_until_earnings': self._calculate_days_until(earnings_base.get('scheduled_date')),
                'earnings_status_display': self._get_status_display(earnings_base.get('earnings_status')),
                'announcement_time_display': self._get_announcement_time_display(earnings_base.get('announcement_time'))
            }
            
            # é»’å­—è»¢æ›åˆ¤å®šã®è©³ç´°åŒ–
            if earnings_base.get('is_black_ink_conversion'):
                enriched['black_ink_details'] = await self._analyze_black_ink_conversion(earnings_base)
            
            # ã‚«ãƒ–ã‚¿ãƒ³ã‹ã‚‰è¿½åŠ ã®è²¡å‹™ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆé«˜å„ªå…ˆåº¦ã®å ´åˆã®ã¿ï¼‰
            priority_score = self._calculate_earnings_priority(earnings_base)
            if priority_score >= 60 and self.config['auto_update_earnings']:
                try:
                    kabutan_data = await self.kabutan_service.fetch_earnings_summary(stock_code)
                    if kabutan_data:
                        enriched['kabutan_data'] = {
                            'latest_results': kabutan_data.get('latest_annual'),
                            'growth_analysis': kabutan_data.get('growth_analysis'),
                            'risk_assessment': kabutan_data.get('risk_assessment')
                        }
                except Exception as e:
                    logger.warning(f"âš ï¸ {stock_code} ã‚«ãƒ–ã‚¿ãƒ³ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # æ¥­ç¸¾äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            if include_forecasts:
                enriched['forecasts'] = await self._get_earnings_forecasts(stock_code, earnings_base['fiscal_year'])
            
            # éå»å®Ÿç¸¾ã¨ã®æ¯”è¼ƒ
            enriched['historical_comparison'] = await self._get_historical_comparison(stock_code)
            
            return enriched
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ±ºç®—ãƒ‡ãƒ¼ã‚¿å¼·åŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return earnings_base
    
    def _calculate_days_until(self, scheduled_date: Any) -> Optional[int]:
        """æ±ºç®—ç™ºè¡¨ã¾ã§ã®æ—¥æ•°ã‚’è¨ˆç®—"""
        try:
            if not scheduled_date:
                return None
            
            if isinstance(scheduled_date, str):
                target_date = datetime.strptime(scheduled_date, '%Y-%m-%d').date()
            elif isinstance(scheduled_date, datetime):
                target_date = scheduled_date.date()
            else:
                target_date = scheduled_date
            
            today = date.today()
            return (target_date - today).days
            
        except Exception:
            return None
    
    def _get_status_display(self, status: str) -> str:
        """æ±ºç®—ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®è¡¨ç¤ºåã‚’å–å¾—"""
        status_map = {
            'scheduled': 'äºˆå®š',
            'announced': 'ç™ºè¡¨æ¸ˆã¿',
            'delayed': 'å»¶æœŸ',
            'cancelled': 'ä¸­æ­¢'
        }
        return status_map.get(status, status)
    
    def _get_announcement_time_display(self, time_code: str) -> str:
        """ç™ºè¡¨æ™‚é–“ã®è¡¨ç¤ºåã‚’å–å¾—"""
        time_map = {
            'pre_market': 'å ´å‰',
            'after_market': 'å ´å¾Œ',
            'trading_hours': 'å ´ä¸­'
        }
        return time_map.get(time_code, time_code)
    
    def _calculate_earnings_priority(self, earnings_data: Dict[str, Any]) -> int:
        """æ±ºç®—ã®å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 0
        
        # é»’å­—è»¢æ›å€™è£œ
        if earnings_data.get('is_black_ink_conversion'):
            score += 40
        
        # ä¸Šå ´å¯¾è±¡ï¼ˆ2.5-5å¹´ä»¥å†…ï¼‰
        if earnings_data.get('is_listing_target'):
            score += 30
        
        # å„ªå…ˆã‚»ã‚¯ã‚¿ãƒ¼
        sector = earnings_data.get('sector', '')
        if sector in self.config['priority_sectors']:
            score += 20
        
        # æ±ºç®—ç™ºè¡¨ã¾ã§ã®æ—¥æ•°
        days_until = self._calculate_days_until(earnings_data.get('scheduled_date'))
        if days_until is not None:
            if days_until <= 7:
                score += 20
            elif days_until <= 14:
                score += 10
        
        # ãƒ­ã‚¸ãƒƒã‚¯Bå¯¾è±¡ãƒ•ãƒ©ã‚°
        if earnings_data.get('is_target_for_logic_b'):
            score += 25
        
        return min(score, 100)  # æœ€å¤§100ç‚¹
    
    async def _analyze_black_ink_conversion(self, earnings_data: Dict[str, Any]) -> Dict[str, Any]:
        """é»’å­—è»¢æ›ã®è©³ç´°åˆ†æ"""
        try:
            stock_code = earnings_data['stock_code']
            
            # Yahoo Finance APIã§è©³ç´°åˆ†æ
            yahoo_analysis = self.earnings_analysis.get_earnings_data(stock_code)
            
            if yahoo_analysis and not yahoo_analysis.get('error'):
                return {
                    'conversion_type': yahoo_analysis.get('conversion_type'),
                    'growth_rate': yahoo_analysis.get('growth_rate'),
                    'profit_change_description': yahoo_analysis.get('profit_change_description'),
                    'trend_analysis': yahoo_analysis.get('trend_analysis'),
                    'operating_income_analysis': yahoo_analysis.get('operating_income'),
                    'quarterly_analysis': yahoo_analysis.get('quarterly')
                }
            else:
                return {
                    'conversion_type': 'unknown',
                    'analysis_available': False,
                    'error': yahoo_analysis.get('error') if yahoo_analysis else 'ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸å¯'
                }
                
        except Exception as e:
            logger.warning(f"âš ï¸ é»’å­—è»¢æ›åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'analysis_available': False, 'error': str(e)}
    
    async def _get_earnings_forecasts(self, stock_code: str, fiscal_year: int) -> Dict[str, Any]:
        """æ¥­ç¸¾äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ—¢å­˜ã®äºˆæƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            forecast_query = """
                SELECT forecast_revision
                FROM earnings_schedule
                WHERE stock_code = :stock_code AND fiscal_year = :fiscal_year
                AND forecast_revision IS NOT NULL
                ORDER BY updated_at DESC
                LIMIT 1
            """
            
            result = await database.fetch_one(
                forecast_query,
                values={"stock_code": stock_code, "fiscal_year": fiscal_year}
            )
            
            forecasts = {
                'has_forecasts': False,
                'revisions': [],
                'accuracy_analysis': None
            }
            
            if result and result['forecast_revision']:
                forecasts['has_forecasts'] = True
                forecasts['revisions'] = result['forecast_revision']
                
                # äºˆæƒ³ç²¾åº¦ã®åˆ†æ
                forecasts['accuracy_analysis'] = self._analyze_forecast_accuracy(
                    result['forecast_revision']
                )
            
            return forecasts
            
        except Exception as e:
            logger.warning(f"âš ï¸ æ¥­ç¸¾äºˆæƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'has_forecasts': False, 'error': str(e)}
    
    def _analyze_forecast_accuracy(self, forecast_revisions: Any) -> Dict[str, Any]:
        """äºˆæƒ³ç²¾åº¦ã‚’åˆ†æ"""
        try:
            if not forecast_revisions or not isinstance(forecast_revisions, list):
                return {'accuracy_available': False}
            
            # äºˆæƒ³ä¿®æ­£å›æ•°
            revision_count = len(forecast_revisions)
            
            # ä¿®æ­£å¹…ã®åˆ†æ
            revision_magnitudes = []
            for revision in forecast_revisions:
                if isinstance(revision, dict) and 'magnitude' in revision:
                    revision_magnitudes.append(abs(revision['magnitude']))
            
            avg_revision = sum(revision_magnitudes) / len(revision_magnitudes) if revision_magnitudes else 0
            
            # ç²¾åº¦è©•ä¾¡
            accuracy_level = 'high'
            if avg_revision > self.config['forecast_accuracy_threshold']:
                accuracy_level = 'low'
            elif avg_revision > self.config['forecast_accuracy_threshold'] / 2:
                accuracy_level = 'medium'
            
            return {
                'accuracy_available': True,
                'revision_count': revision_count,
                'average_revision_magnitude': round(avg_revision, 3),
                'accuracy_level': accuracy_level
            }
            
        except Exception as e:
            return {'accuracy_available': False, 'error': str(e)}
    
    async def _get_historical_comparison(self, stock_code: str) -> Dict[str, Any]:
        """éå»å®Ÿç¸¾ã¨ã®æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            # éå»5å¹´ã®æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            historical_query = """
                SELECT fiscal_year, fiscal_quarter, revenue_actual, profit_actual
                FROM earnings_schedule
                WHERE stock_code = :stock_code
                AND revenue_actual IS NOT NULL
                AND fiscal_year >= :min_year
                ORDER BY fiscal_year DESC, 
                    CASE fiscal_quarter 
                        WHEN 'FY' THEN 5
                        WHEN 'Q4' THEN 4
                        WHEN 'Q3' THEN 3
                        WHEN 'Q2' THEN 2
                        WHEN 'Q1' THEN 1
                        ELSE 0
                    END DESC
                LIMIT 20
            """
            
            min_year = datetime.now().year - self.config['max_historical_years']
            
            results = await database.fetch_all(
                historical_query,
                values={"stock_code": stock_code, "min_year": min_year}
            )
            
            if not results:
                return {'historical_data_available': False}
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’å¹´åº¦ãƒ»å››åŠæœŸåˆ¥ã«æ•´ç†
            annual_data = []
            quarterly_data = []
            
            for row in results:
                row_dict = dict(row)
                if row['fiscal_quarter'] == 'FY':
                    annual_data.append(row_dict)
                else:
                    quarterly_data.append(row_dict)
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            revenue_trend = self._analyze_trend([r['revenue_actual'] for r in annual_data[:3]])
            profit_trend = self._analyze_trend([r['profit_actual'] for r in annual_data[:3]])
            
            return {
                'historical_data_available': True,
                'years_of_data': len(annual_data),
                'quarters_of_data': len(quarterly_data),
                'latest_annual': annual_data[0] if annual_data else None,
                'latest_quarterly': quarterly_data[0] if quarterly_data else None,
                'trends': {
                    'revenue_trend': revenue_trend,
                    'profit_trend': profit_trend
                },
                'growth_rates': self._calculate_historical_growth_rates(annual_data)
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ éå»å®Ÿç¸¾æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'historical_data_available': False, 'error': str(e)}
    
    def _analyze_trend(self, values: List[float]) -> str:
        """æ•°å€¤ãƒªã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ"""
        if len(values) < 2:
            return 'insufficient_data'
        
        # é€£ç¶šæˆé•·åˆ¤å®š
        is_growing = True
        for i in range(len(values) - 1):
            if values[i] <= values[i + 1]:
                is_growing = False
                break
        
        if is_growing:
            return 'growing'
        
        # é€£ç¶šæ¸›å°‘åˆ¤å®š
        is_declining = True
        for i in range(len(values) - 1):
            if values[i] >= values[i + 1]:
                is_declining = False
                break
        
        if is_declining:
            return 'declining'
        
        return 'volatile'
    
    def _calculate_historical_growth_rates(self, annual_data: List[Dict[str, Any]]) -> Dict[str, float]:
        """éå»ã®æˆé•·ç‡ã‚’è¨ˆç®—"""
        growth_rates = {
            'revenue_1y': None,
            'revenue_3y_cagr': None,
            'profit_1y': None,
            'profit_3y_cagr': None
        }
        
        if len(annual_data) >= 2:
            latest = annual_data[0]
            previous = annual_data[1]
            
            # 1å¹´æˆé•·ç‡
            if latest['revenue_actual'] and previous['revenue_actual']:
                growth_rates['revenue_1y'] = ((latest['revenue_actual'] - previous['revenue_actual']) / 
                                            abs(previous['revenue_actual'])) * 100
            
            if latest['profit_actual'] and previous['profit_actual'] and previous['profit_actual'] != 0:
                growth_rates['profit_1y'] = ((latest['profit_actual'] - previous['profit_actual']) / 
                                           abs(previous['profit_actual'])) * 100
        
        # 3å¹´CAGR
        if len(annual_data) >= 4:
            latest = annual_data[0]
            three_years_ago = annual_data[3]
            
            if latest['revenue_actual'] and three_years_ago['revenue_actual'] and three_years_ago['revenue_actual'] > 0:
                growth_rates['revenue_3y_cagr'] = (((latest['revenue_actual'] / three_years_ago['revenue_actual']) ** (1/3)) - 1) * 100
            
            if (latest['profit_actual'] and three_years_ago['profit_actual'] and 
                three_years_ago['profit_actual'] > 0 and latest['profit_actual'] > 0):
                growth_rates['profit_3y_cagr'] = (((latest['profit_actual'] / three_years_ago['profit_actual']) ** (1/3)) - 1) * 100
        
        # å€¤ã‚’ä¸¸ã‚ã‚‹
        for key, value in growth_rates.items():
            if value is not None:
                growth_rates[key] = round(value, 2)
        
        return growth_rates
    
    async def get_black_ink_conversion_pipeline(self) -> Dict[str, Any]:
        """é»’å­—è»¢æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æ"""
        try:
            logger.info("ğŸ’° é»’å­—è»¢æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æé–‹å§‹")
            
            # é»’å­—è»¢æ›å€™è£œã‚’å–å¾—
            pipeline_query = """
                SELECT 
                    e.*,
                    l.market,
                    l.sector,
                    l.years_since_listing,
                    l.is_target as is_listing_target
                FROM earnings_schedule e
                LEFT JOIN listing_dates l ON e.stock_code = l.stock_code
                WHERE (
                    e.is_black_ink_conversion = true
                    OR e.is_target_for_logic_b = true
                    OR (e.profit_previous <= 0 AND e.profit_estimate > 0)
                )
                AND e.fiscal_year >= :current_year - 1
                ORDER BY 
                    CASE 
                        WHEN e.is_black_ink_conversion = true THEN 1
                        WHEN e.is_target_for_logic_b = true THEN 2
                        ELSE 3
                    END,
                    e.scheduled_date ASC
            """
            
            results = await database.fetch_all(
                pipeline_query,
                values={"current_year": datetime.now().year}
            )
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–
            pipeline_data = {
                'summary': {
                    'total_candidates': len(results),
                    'confirmed_conversions': 0,
                    'probable_conversions': 0,
                    'potential_conversions': 0
                },
                'by_stage': {
                    'confirmed': [],    # ç¢ºå®Ÿãªé»’å­—è»¢æ›
                    'probable': [],     # å¯èƒ½æ€§é«˜ã„
                    'potential': []     # æ½œåœ¨çš„
                },
                'by_sector': {},
                'by_timing': {
                    'next_30_days': [],
                    'next_90_days': [],
                    'beyond_90_days': []
                },
                'risk_analysis': {
                    'high_confidence': [],
                    'medium_confidence': [],
                    'low_confidence': []
                }
            }
            
            # å„å€™è£œã‚’åˆ†æãƒ»åˆ†é¡
            for row in results:
                candidate = dict(row)
                
                # ç¢ºå®Ÿæ€§ã®è©•ä¾¡
                confidence_level = self._assess_conversion_confidence(candidate)
                stage = self._determine_conversion_stage(candidate)
                
                candidate['confidence_level'] = confidence_level
                candidate['conversion_stage'] = stage
                
                # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥åˆ†é¡
                pipeline_data['by_stage'][stage].append(candidate)
                pipeline_data['summary'][f'{stage}_conversions'] += 1
                
                # æ¥­ç¨®åˆ¥åˆ†é¡
                sector = candidate.get('sector', 'æœªåˆ†é¡')
                if sector not in pipeline_data['by_sector']:
                    pipeline_data['by_sector'][sector] = []
                pipeline_data['by_sector'][sector].append(candidate)
                
                # ã‚¿ã‚¤ãƒŸãƒ³ã‚°åˆ¥åˆ†é¡
                days_until = self._calculate_days_until(candidate.get('scheduled_date'))
                if days_until is not None:
                    if days_until <= 30:
                        pipeline_data['by_timing']['next_30_days'].append(candidate)
                    elif days_until <= 90:
                        pipeline_data['by_timing']['next_90_days'].append(candidate)
                    else:
                        pipeline_data['by_timing']['beyond_90_days'].append(candidate)
                
                # ãƒªã‚¹ã‚¯åˆ†æ
                pipeline_data['risk_analysis'][confidence_level].append(candidate)
            
            logger.info(f"âœ… é»’å­—è»¢æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æå®Œäº†: {len(results)} å€™è£œ")
            return pipeline_data
            
        except Exception as e:
            logger.error(f"âŒ é»’å­—è»¢æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def _assess_conversion_confidence(self, candidate: Dict[str, Any]) -> str:
        """é»’å­—è»¢æ›ã®ç¢ºå®Ÿæ€§ã‚’è©•ä¾¡"""
        score = 0
        
        # ç¢ºå®Ÿãªé»’å­—è»¢æ›ãƒ•ãƒ©ã‚°
        if candidate.get('is_black_ink_conversion'):
            score += 60
        
        # å‰æœŸèµ¤å­—ã€ä»ŠæœŸäºˆæƒ³é»’å­—
        if (candidate.get('profit_previous', 0) <= 0 and 
            candidate.get('profit_estimate', 0) > 0):
            score += 40
        
        # ãƒ­ã‚¸ãƒƒã‚¯Bå¯¾è±¡
        if candidate.get('is_target_for_logic_b'):
            score += 30
        
        # ä¸Šå ´å¹´æ•°ï¼ˆè‹¥ã„ä¼æ¥­ã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼‰
        years_since = candidate.get('years_since_listing', 10)
        if years_since <= 3:
            score += 20
        elif years_since <= 5:
            score += 10
        
        # å„ªå…ˆã‚»ã‚¯ã‚¿ãƒ¼
        if candidate.get('sector') in self.config['priority_sectors']:
            score += 15
        
        # ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if score >= 80:
            return 'high_confidence'
        elif score >= 50:
            return 'medium_confidence'
        else:
            return 'low_confidence'
    
    def _determine_conversion_stage(self, candidate: Dict[str, Any]) -> str:
        """è»¢æ›ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’åˆ¤å®š"""
        # æ—¢ã«ç™ºè¡¨æ¸ˆã¿ã§é»’å­—è»¢æ›ç¢ºèª
        if (candidate.get('earnings_status') == 'announced' and 
            candidate.get('is_black_ink_conversion')):
            return 'confirmed'
        
        # ç™ºè¡¨äºˆå®šã§é«˜ç¢ºåº¦
        if (candidate.get('earnings_status') == 'scheduled' and 
            candidate.get('is_black_ink_conversion')):
            return 'probable'
        
        # ãã®ä»–ã®å€™è£œ
        return 'potential'
    
    async def update_earnings_from_external_sources(self, stock_codes: Optional[List[str]] = None) -> Dict[str, Any]:
        """å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        try:
            logger.info("ğŸ”„ å¤–éƒ¨ã‚½ãƒ¼ã‚¹æ±ºç®—ãƒ‡ãƒ¼ã‚¿æ›´æ–°é–‹å§‹")
            
            # å¯¾è±¡éŠ˜æŸ„ã®æ±ºå®š
            if not stock_codes:
                # å„ªå…ˆåº¦ã®é«˜ã„éŠ˜æŸ„ã‚’è‡ªå‹•é¸æŠ
                target_query = """
                    SELECT DISTINCT stock_code
                    FROM earnings_schedule
                    WHERE (
                        is_black_ink_conversion = true
                        OR is_target_for_logic_b = true
                        OR scheduled_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '30 days'
                    )
                    ORDER BY 
                        CASE 
                            WHEN is_black_ink_conversion = true THEN 1
                            WHEN is_target_for_logic_b = true THEN 2
                            ELSE 3
                        END
                    LIMIT 20
                """
                
                results = await database.fetch_all(target_query)
                stock_codes = [row['stock_code'] for row in results]
            
            # æ›´æ–°çµ±è¨ˆ
            update_stats = {
                'total_requested': len(stock_codes),
                'irbank_updates': 0,
                'kabutan_updates': 0,
                'errors': 0,
                'successful_stocks': []
            }
            
            # å„éŠ˜æŸ„ã®æ›´æ–°
            for stock_code in stock_codes:
                try:
                    # IRãƒãƒ³ã‚¯ã‹ã‚‰é©æ™‚é–‹ç¤ºæƒ…å ±ã‚’å–å¾—
                    disclosure_info = await self.irbank_service.fetch_disclosure_info(stock_code, days_back=14)
                    if disclosure_info:
                        update_stats['irbank_updates'] += len(disclosure_info)
                    
                    # ã‚«ãƒ–ã‚¿ãƒ³ã‹ã‚‰æ±ºç®—ã‚µãƒãƒªãƒ¼ã‚’å–å¾—
                    earnings_summary = await self.kabutan_service.fetch_earnings_summary(stock_code)
                    if earnings_summary:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°
                        saved = await self.kabutan_service.save_earnings_to_database(earnings_summary)
                        if saved:
                            update_stats['kabutan_updates'] += 1
                            update_stats['successful_stocks'].append(stock_code)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ {stock_code} æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    update_stats['errors'] += 1
                    continue
            
            logger.info(f"âœ… å¤–éƒ¨ã‚½ãƒ¼ã‚¹æ›´æ–°å®Œäº†: {update_stats}")
            return update_stats
            
        except Exception as e:
            logger.error(f"âŒ å¤–éƒ¨ã‚½ãƒ¼ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    async def get_service_configuration(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹è¨­å®šã‚’å–å¾—"""
        return {
            'service_name': 'å¼·åŒ–ç‰ˆæ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹',
            'version': '1.0.0',
            'configuration': self.config,
            'capabilities': [
                'åŒ…æ‹¬çš„æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼',
                'é»’å­—è»¢æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æ',
                'IRãƒãƒ³ã‚¯ãƒ»ã‚«ãƒ–ã‚¿ãƒ³çµ±åˆ',
                'æ¥­ç¸¾äºˆæƒ³ç²¾åº¦åˆ†æ',
                'éå»å®Ÿç¸¾æ¯”è¼ƒåˆ†æ'
            ],
            'last_updated': datetime.now().isoformat()
        }

# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
async def test_enhanced_earnings_service():
    """å¼·åŒ–ç‰ˆæ±ºç®—ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    service = EnhancedEarningsService()
    
    logger.info("=== å¼·åŒ–ç‰ˆæ±ºç®—ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å–å¾—ãƒ†ã‚¹ãƒˆ
        calendar = await service.get_comprehensive_earnings_calendar()
        logger.info(f"æ±ºç®—ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼: {calendar['summary']['total_earnings']} ä»¶")
        
        # é»’å­—è»¢æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆ†æãƒ†ã‚¹ãƒˆ
        pipeline = await service.get_black_ink_conversion_pipeline()
        logger.info(f"é»’å­—è»¢æ›å€™è£œ: {pipeline['summary']['total_candidates']} ä»¶")
        
        # å¤–éƒ¨ã‚½ãƒ¼ã‚¹æ›´æ–°ãƒ†ã‚¹ãƒˆ
        update_result = await service.update_earnings_from_external_sources(['7203', '6758'])
        logger.info(f"å¤–éƒ¨ã‚½ãƒ¼ã‚¹æ›´æ–°: {update_result}")
        
        # ã‚µãƒ¼ãƒ“ã‚¹è¨­å®šç¢ºèª
        config = await service.get_service_configuration()
        logger.info(f"ã‚µãƒ¼ãƒ“ã‚¹è¨­å®š: {config['service_name']}")
        
        logger.info("âœ… å¼·åŒ–ç‰ˆæ±ºç®—ã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_enhanced_earnings_service())