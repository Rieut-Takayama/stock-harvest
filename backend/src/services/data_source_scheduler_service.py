"""
å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è‡ªå‹•æ›´æ–°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹
å®šæœŸçš„ã«IRãƒãƒ³ã‚¯ãƒ»ã‚«ãƒ–ã‚¿ãƒ³ãƒ»JSEç­‰ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å–å¾—ãƒ»æ›´æ–°
"""

import logging
import asyncio
from datetime import datetime, timedelta, time
from typing import Dict, List, Optional, Any
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from .irbank_integration_service import IRBankIntegrationService
from .kabutan_integration_service import KabutanIntegrationService
from .listing_data_service import ListingDataService
from .price_limit_service import PriceLimitService
from ..database.config import database
from ..database.tables import stock_master, earnings_schedule
from ..lib.logger import logger

class DataSourceSchedulerService:
    """å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è‡ªå‹•æ›´æ–°å°‚é–€ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.is_running = False
        
        # å„ç¨®é€£æºã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
        self.irbank_service = IRBankIntegrationService()
        self.kabutan_service = KabutanIntegrationService()
        self.listing_service = ListingDataService()
        self.price_limit_service = PriceLimitService()
        
        # å®Ÿè¡Œå±¥æ­´ã¨çµ±è¨ˆ
        self.execution_history = []
        self.execution_stats = {
            'total_executions': 0,
            'successful_executions': 0,
            'failed_executions': 0,
            'last_execution_time': None,
            'last_success_time': None,
            'last_error': None
        }
        
        # è¨­å®š
        self.config = {
            'use_sample_data': True,  # æœ¬ç•ªã§ã¯ False ã«è¨­å®š
            'max_concurrent_requests': 3,
            'error_retry_attempts': 2,
            'batch_size': 10,
            'enable_weekends': False  # åœŸæ—¥ã®å®Ÿè¡Œã‚’ç„¡åŠ¹åŒ–
        }
    
    def setup_schedules(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¨­å®š"""
        try:
            logger.info("ğŸ“… ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šé–‹å§‹")
            
            # 1. ä¸Šå ´æ—¥ãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼ˆé€±æ¬¡ã€æœˆæ›œæ—¥ 6:00ï¼‰
            self.scheduler.add_job(
                self._update_listing_dates,
                CronTrigger(day_of_week='mon', hour=6, minute=0),
                id='listing_dates_weekly',
                name='ä¸Šå ´æ—¥ãƒ‡ãƒ¼ã‚¿é€±æ¬¡æ›´æ–°',
                replace_existing=True
            )
            
            # 2. æ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°ï¼ˆæ—¥æ¬¡ã€å¹³æ—¥ 7:00ï¼‰
            self.scheduler.add_job(
                self._update_earnings_schedule,
                CronTrigger(day_of_week='mon-fri', hour=7, minute=0),
                id='earnings_schedule_daily',
                name='æ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ—¥æ¬¡æ›´æ–°',
                replace_existing=True
            )
            
            # 3. åˆ¶é™å€¤å¹…æ›´æ–°ï¼ˆå¹³æ—¥ã®å–å¼•æ™‚é–“ä¸­ã€30åˆ†é–“éš”ï¼‰
            self.scheduler.add_job(
                self._update_price_limits_batch,
                CronTrigger(day_of_week='mon-fri', hour='9-15', minute='*/30'),
                id='price_limits_trading_hours',
                name='åˆ¶é™å€¤å¹…æ›´æ–°ï¼ˆå–å¼•æ™‚é–“ä¸­ï¼‰',
                replace_existing=True
            )
            
            # 4. IRãƒãƒ³ã‚¯é©æ™‚é–‹ç¤ºæƒ…å ±å–å¾—ï¼ˆå¹³æ—¥ 8:00, 12:00, 17:00ï¼‰
            self.scheduler.add_job(
                self._fetch_disclosure_updates,
                CronTrigger(day_of_week='mon-fri', hour='8,12,17', minute=0),
                id='disclosure_updates_daily',
                name='é©æ™‚é–‹ç¤ºæƒ…å ±æ›´æ–°',
                replace_existing=True
            )
            
            # 5. ã‚«ãƒ–ã‚¿ãƒ³æ±ºç®—ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå¹³æ—¥ 20:00ï¼‰
            self.scheduler.add_job(
                self._update_earnings_data_batch,
                CronTrigger(day_of_week='mon-fri', hour=20, minute=0),
                id='earnings_data_evening',
                name='æ±ºç®—ãƒ‡ãƒ¼ã‚¿å¤œé–“æ›´æ–°',
                replace_existing=True
            )
            
            # 6. çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆæ—¥æ¬¡ã€å¹³æ—¥ 23:00ï¼‰
            self.scheduler.add_job(
                self._generate_daily_report,
                CronTrigger(day_of_week='mon-fri', hour=23, minute=0),
                id='daily_report_generation',
                name='æ—¥æ¬¡çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ',
                replace_existing=True
            )
            
            # 7. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆ15åˆ†é–“éš”ï¼‰
            self.scheduler.add_job(
                self._health_check,
                IntervalTrigger(minutes=15),
                id='health_check_interval',
                name='ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯',
                replace_existing=True
            )
            
            logger.info("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    async def start_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’é–‹å§‹"""
        try:
            if not self.is_running:
                self.setup_schedules()
                self.scheduler.start()
                self.is_running = True
                logger.info("ğŸš€ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹")
                
                # åˆæœŸå®Ÿè¡Œãƒ†ã‚¹ãƒˆ
                await self._initial_health_check()
            else:
                logger.warning("âš ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã¯æ—¢ã«å®Ÿè¡Œä¸­ã§ã™")
                
        except Exception as e:
            logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    async def stop_scheduler(self):
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’åœæ­¢"""
        try:
            if self.is_running:
                self.scheduler.shutdown()
                self.is_running = False
                logger.info("ğŸ›‘ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢")
            else:
                logger.warning("âš ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã¯å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
        except Exception as e:
            logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    async def _update_listing_dates(self):
        """ä¸Šå ´æ—¥ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        job_name = "ä¸Šå ´æ—¥ãƒ‡ãƒ¼ã‚¿æ›´æ–°"
        logger.info(f"ğŸ“… {job_name} é–‹å§‹")
        
        try:
            start_time = datetime.now()
            
            # ä¸Šå ´æ—¥ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Ÿè¡Œ
            result = await self.listing_service.update_listing_data(
                use_sample=self.config['use_sample_data']
            )
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # å®Ÿè¡Œå±¥æ­´ã«è¨˜éŒ²
            self._record_execution(job_name, True, execution_time, result)
            
            logger.info(f"âœ… {job_name} å®Œäº†: {result}")
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._record_execution(job_name, False, execution_time, None, str(e))
            logger.error(f"âŒ {job_name} ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _update_earnings_schedule(self):
        """æ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ›´æ–°"""
        job_name = "æ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ›´æ–°"
        logger.info(f"ğŸ“Š {job_name} é–‹å§‹")
        
        try:
            start_time = datetime.now()
            
            # IRãƒãƒ³ã‚¯ã‹ã‚‰æ±ºç®—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å–å¾—
            earnings_data = await self.irbank_service.fetch_earnings_schedule()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            save_result = await self.irbank_service.save_earnings_to_database(earnings_data)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                'earnings_fetched': len(earnings_data),
                'save_result': save_result
            }
            
            self._record_execution(job_name, True, execution_time, result)
            
            logger.info(f"âœ… {job_name} å®Œäº†: {len(earnings_data)} ä»¶å–å¾—")
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._record_execution(job_name, False, execution_time, None, str(e))
            logger.error(f"âŒ {job_name} ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _update_price_limits_batch(self):
        """åˆ¶é™å€¤å¹…ã‚’ãƒãƒƒãƒæ›´æ–°"""
        job_name = "åˆ¶é™å€¤å¹…ãƒãƒƒãƒæ›´æ–°"
        
        # åœŸæ—¥ã¯å®Ÿè¡Œã—ãªã„
        if not self.config['enable_weekends'] and datetime.now().weekday() >= 5:
            logger.info(f"â­ï¸ {job_name} ã‚¹ã‚­ãƒƒãƒ—ï¼ˆåœŸæ—¥ï¼‰")
            return
        
        logger.info(f"ğŸ’° {job_name} é–‹å§‹")
        
        try:
            start_time = datetime.now()
            
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—
            active_stocks = await self._get_active_stocks(limit=self.config['batch_size'])
            
            # å„éŠ˜æŸ„ã®ç¾åœ¨ä¾¡æ ¼ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
            stock_price_data = []
            for stock in active_stocks:
                # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€æ ªä¾¡APIã‹ã‚‰ç¾åœ¨ä¾¡æ ¼ã‚’å–å¾—
                sample_price = 1000 + (hash(stock['code']) % 5000)  # ã‚µãƒ³ãƒ—ãƒ«ä¾¡æ ¼ç”Ÿæˆ
                stock_price_data.append({
                    'code': stock['code'],
                    'price': sample_price
                })
            
            # åˆ¶é™å€¤å¹…ã‚’ä¸€æ‹¬æ›´æ–°
            result = await self.price_limit_service.batch_update_price_limits(stock_price_data)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            self._record_execution(job_name, True, execution_time, result)
            
            logger.info(f"âœ… {job_name} å®Œäº†: {result['updated'] + result['inserted']} ä»¶æ›´æ–°")
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._record_execution(job_name, False, execution_time, None, str(e))
            logger.error(f"âŒ {job_name} ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _fetch_disclosure_updates(self):
        """é©æ™‚é–‹ç¤ºæƒ…å ±ã‚’å–å¾—"""
        job_name = "é©æ™‚é–‹ç¤ºæƒ…å ±æ›´æ–°"
        logger.info(f"ğŸ“¢ {job_name} é–‹å§‹")
        
        try:
            start_time = datetime.now()
            
            # æ³¨ç›®éŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—
            target_stocks = await self._get_target_stocks_for_disclosure()
            
            total_disclosures = 0
            for stock in target_stocks[:self.config['batch_size']]:
                try:
                    # IRãƒãƒ³ã‚¯ã‹ã‚‰é©æ™‚é–‹ç¤ºã‚’å–å¾—
                    disclosures = await self.irbank_service.fetch_disclosure_info(
                        stock['code'], days_back=7
                    )
                    total_disclosures += len(disclosures)
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ {stock['code']} é©æ™‚é–‹ç¤ºå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                'stocks_checked': len(target_stocks[:self.config['batch_size']]),
                'disclosures_found': total_disclosures
            }
            
            self._record_execution(job_name, True, execution_time, result)
            
            logger.info(f"âœ… {job_name} å®Œäº†: {total_disclosures} ä»¶å–å¾—")
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._record_execution(job_name, False, execution_time, None, str(e))
            logger.error(f"âŒ {job_name} ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _update_earnings_data_batch(self):
        """æ±ºç®—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒƒãƒæ›´æ–°"""
        job_name = "æ±ºç®—ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒæ›´æ–°"
        logger.info(f"ğŸ’¼ {job_name} é–‹å§‹")
        
        try:
            start_time = datetime.now()
            
            # æ±ºç®—ç™ºè¡¨äºˆå®šã®éŠ˜æŸ„ã‚’å–å¾—
            earnings_due_stocks = await self._get_earnings_due_stocks()
            
            total_updated = 0
            for stock in earnings_due_stocks[:self.config['batch_size']]:
                try:
                    # ã‚«ãƒ–ã‚¿ãƒ³ã‹ã‚‰æ±ºç®—ã‚µãƒãƒªãƒ¼ã‚’å–å¾—
                    earnings_summary = await self.kabutan_service.fetch_earnings_summary(stock['code'])
                    
                    if earnings_summary:
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                        saved = await self.kabutan_service.save_earnings_to_database(earnings_summary)
                        if saved:
                            total_updated += 1
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å¾…æ©Ÿ
                    await asyncio.sleep(2)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ {stock['code']} æ±ºç®—ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            result = {
                'stocks_checked': len(earnings_due_stocks[:self.config['batch_size']]),
                'earnings_updated': total_updated
            }
            
            self._record_execution(job_name, True, execution_time, result)
            
            logger.info(f"âœ… {job_name} å®Œäº†: {total_updated} ä»¶æ›´æ–°")
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._record_execution(job_name, False, execution_time, None, str(e))
            logger.error(f"âŒ {job_name} ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _generate_daily_report(self):
        """æ—¥æ¬¡çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        job_name = "æ—¥æ¬¡çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"
        logger.info(f"ğŸ“‹ {job_name} é–‹å§‹")
        
        try:
            start_time = datetime.now()
            
            # å„ç¨®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            listing_stats = await self.listing_service.get_listing_stats()
            price_limit_stats = await self.price_limit_service.get_price_limit_stats()
            scheduler_stats = self.get_execution_statistics()
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            report = {
                'date': datetime.now().strftime('%Y-%m-%d'),
                'listing_data': listing_stats,
                'price_limits': price_limit_stats,
                'scheduler_performance': scheduler_stats,
                'generated_at': datetime.now()
            }
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            logger.info(f"ğŸ“Š æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ:\n"
                       f"  ä¸Šå ´éŠ˜æŸ„: {listing_stats['total_stocks']} ä»¶\n"
                       f"  ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡: {listing_stats['target_stocks']} ä»¶\n"
                       f"  åˆ¶é™å€¤å¹…ãƒ‡ãƒ¼ã‚¿: {price_limit_stats['total_stocks']} ä»¶\n"
                       f"  ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼å®Ÿè¡Œå›æ•°: {scheduler_stats['total_executions']} å›\n"
                       f"  æˆåŠŸç‡: {scheduler_stats['success_rate']:.1f}%")
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            self._record_execution(job_name, True, execution_time, report)
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            self._record_execution(job_name, False, execution_time, None, str(e))
            logger.error(f"âŒ {job_name} ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _health_check(self):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        try:
            # å„ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ç¢ºèª
            irbank_status = await self.irbank_service.get_service_status()
            kabutan_status = await self.kabutan_service.get_service_status()
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
            db_healthy = await self._check_database_connection()
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®çŠ¶æ…‹
            scheduler_healthy = self.is_running and self.scheduler.running
            
            overall_health = all([
                irbank_status['status'] == 'active',
                kabutan_status['status'] == 'active',
                db_healthy,
                scheduler_healthy
            ])
            
            if not overall_health:
                logger.warning("âš ï¸ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯è­¦å‘Š: ä¸€éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    async def _initial_health_check(self):
        """åˆæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        logger.info("ğŸ¥ åˆæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
            db_healthy = await self._check_database_connection()
            if not db_healthy:
                raise Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—")
            
            # å„ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ç¢ºèª
            irbank_status = await self.irbank_service.get_service_status()
            kabutan_status = await self.kabutan_service.get_service_status()
            
            logger.info("âœ… åˆæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Œäº†")
            logger.info(f"  IRãƒãƒ³ã‚¯ã‚µãƒ¼ãƒ“ã‚¹: {irbank_status['status']}")
            logger.info(f"  ã‚«ãƒ–ã‚¿ãƒ³ã‚µãƒ¼ãƒ“ã‚¹: {kabutan_status['status']}")
            logger.info(f"  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: æ¥ç¶šOK")
            
        except Exception as e:
            logger.error(f"âŒ åˆæœŸãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¤±æ•—: {str(e)}")
            raise
    
    async def _get_active_stocks(self, limit: int = 50) -> List[Dict[str, Any]]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        try:
            query = """
                SELECT stock_code as code, company_name as name
                FROM listing_dates 
                WHERE is_target = true 
                ORDER BY years_since_listing ASC 
                LIMIT :limit
            """
            
            results = await database.fetch_all(query, values={"limit": limit})
            
            return [
                {'code': row['code'], 'name': row['name']}
                for row in results
            ]
            
        except Exception as e:
            logger.error(f"âŒ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–éŠ˜æŸ„å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    async def _get_target_stocks_for_disclosure(self) -> List[Dict[str, Any]]:
        """é©æ™‚é–‹ç¤ºç›£è¦–å¯¾è±¡ã®éŠ˜æŸ„ã‚’å–å¾—"""
        try:
            # éå»30æ—¥ä»¥å†…ã«æ±ºç®—ç™ºè¡¨ãŒã‚ã‚‹ã€ã¾ãŸã¯é»’å­—è»¢æ›å€™è£œã®éŠ˜æŸ„
            query = """
                SELECT DISTINCT e.stock_code as code, e.stock_name as name
                FROM earnings_schedule e
                WHERE (
                    e.scheduled_date >= CURRENT_DATE - INTERVAL '30 days'
                    OR e.is_target_for_logic_b = true
                )
                ORDER BY e.scheduled_date ASC
            """
            
            results = await database.fetch_all(query)
            
            return [
                {'code': row['code'], 'name': row['name']}
                for row in results
            ]
            
        except Exception as e:
            logger.error(f"âŒ é©æ™‚é–‹ç¤ºå¯¾è±¡éŠ˜æŸ„å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    async def _get_earnings_due_stocks(self) -> List[Dict[str, Any]]:
        """æ±ºç®—ç™ºè¡¨äºˆå®šéŠ˜æŸ„ã‚’å–å¾—"""
        try:
            # ä»Šå¾Œ7æ—¥ä»¥å†…ã«æ±ºç®—ç™ºè¡¨äºˆå®šã€ã¾ãŸã¯æœ€è¿‘ç™ºè¡¨æ¸ˆã¿ã§ãƒ‡ãƒ¼ã‚¿æœªå–å¾—ã®éŠ˜æŸ„
            query = """
                SELECT stock_code as code, stock_name as name, scheduled_date
                FROM earnings_schedule
                WHERE (
                    scheduled_date BETWEEN CURRENT_DATE AND CURRENT_DATE + INTERVAL '7 days'
                    OR (
                        scheduled_date >= CURRENT_DATE - INTERVAL '3 days'
                        AND earnings_status = 'scheduled'
                    )
                )
                ORDER BY scheduled_date ASC
            """
            
            results = await database.fetch_all(query)
            
            return [
                {
                    'code': row['code'], 
                    'name': row['name'],
                    'scheduled_date': row['scheduled_date']
                }
                for row in results
            ]
            
        except Exception as e:
            logger.error(f"âŒ æ±ºç®—äºˆå®šéŠ˜æŸ„å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    async def _check_database_connection(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª"""
        try:
            await database.fetch_one("SELECT 1 as test")
            return True
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def _record_execution(self, job_name: str, success: bool, execution_time: float, result: Any = None, error: str = None):
        """å®Ÿè¡Œå±¥æ­´ã‚’è¨˜éŒ²"""
        execution_record = {
            'job_name': job_name,
            'timestamp': datetime.now(),
            'success': success,
            'execution_time': execution_time,
            'result': result,
            'error': error
        }
        
        self.execution_history.append(execution_record)
        
        # å±¥æ­´ã¯æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        if len(self.execution_history) > 100:
            self.execution_history = self.execution_history[-100:]
        
        # çµ±è¨ˆã‚’æ›´æ–°
        self.execution_stats['total_executions'] += 1
        if success:
            self.execution_stats['successful_executions'] += 1
            self.execution_stats['last_success_time'] = datetime.now()
        else:
            self.execution_stats['failed_executions'] += 1
            self.execution_stats['last_error'] = error
        
        self.execution_stats['last_execution_time'] = datetime.now()
    
    def get_execution_statistics(self) -> Dict[str, Any]:
        """å®Ÿè¡Œçµ±è¨ˆã‚’å–å¾—"""
        total = self.execution_stats['total_executions']
        success_rate = (self.execution_stats['successful_executions'] / total * 100) if total > 0 else 0
        
        return {
            'total_executions': total,
            'successful_executions': self.execution_stats['successful_executions'],
            'failed_executions': self.execution_stats['failed_executions'],
            'success_rate': round(success_rate, 2),
            'last_execution_time': self.execution_stats['last_execution_time'],
            'last_success_time': self.execution_stats['last_success_time'],
            'last_error': self.execution_stats['last_error']
        }
    
    def get_scheduled_jobs(self) -> List[Dict[str, Any]]:
        """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¸ˆã¿ã‚¸ãƒ§ãƒ–ä¸€è¦§ã‚’å–å¾—"""
        if not self.is_running:
            return []
        
        jobs = []
        for job in self.scheduler.get_jobs():
            jobs.append({
                'id': job.id,
                'name': job.name,
                'next_run_time': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger)
            })
        
        return jobs
    
    async def execute_job_manually(self, job_id: str) -> Dict[str, Any]:
        """ã‚¸ãƒ§ãƒ–ã‚’æ‰‹å‹•å®Ÿè¡Œ"""
        try:
            job = self.scheduler.get_job(job_id)
            if not job:
                return {'success': False, 'message': f'ã‚¸ãƒ§ãƒ– {job_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}
            
            logger.info(f"ğŸ”§ æ‰‹å‹•å®Ÿè¡Œ: {job.name}")
            
            # ã‚¸ãƒ§ãƒ–ã‚’å³åº§ã«å®Ÿè¡Œ
            job.modify(next_run_time=datetime.now())
            
            return {
                'success': True,
                'message': f'ã‚¸ãƒ§ãƒ– {job.name} ã‚’æ‰‹å‹•å®Ÿè¡Œã—ã¾ã—ãŸ',
                'job_id': job_id
            }
            
        except Exception as e:
            logger.error(f"âŒ ã‚¸ãƒ§ãƒ–æ‰‹å‹•å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'success': False, 'message': str(e)}
    
    async def get_service_status(self) -> Dict[str, Any]:
        """ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            'service_name': 'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼',
            'is_running': self.is_running,
            'scheduler_running': self.scheduler.running if self.is_running else False,
            'total_jobs': len(self.scheduler.get_jobs()) if self.is_running else 0,
            'execution_statistics': self.get_execution_statistics(),
            'configuration': self.config,
            'last_updated': datetime.now().isoformat()
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
data_source_scheduler = DataSourceSchedulerService()

# ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
async def test_scheduler():
    """ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    scheduler = DataSourceSchedulerService()
    
    logger.info("=== ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    try:
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹
        await scheduler.start_scheduler()
        
        # çŠ¶æ…‹ç¢ºèª
        status = await scheduler.get_service_status()
        logger.info(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼çŠ¶æ…‹: {status['is_running']}")
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¸ˆã¿ã‚¸ãƒ§ãƒ–ä¸€è¦§
        jobs = scheduler.get_scheduled_jobs()
        logger.info(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æ¸ˆã¿ã‚¸ãƒ§ãƒ–: {len(jobs)} ä»¶")
        
        # å°‘ã—å¾…æ©Ÿ
        await asyncio.sleep(5)
        
        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢
        await scheduler.stop_scheduler()
        
        logger.info("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        logger.error(f"âŒ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        await scheduler.stop_scheduler()

if __name__ == "__main__":
    asyncio.run(test_scheduler())