"""
æ‰‹å‹•ã‚¹ã‚³ã‚¢è©•ä¾¡æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ
Stock Harvest AI - å®Ÿãƒ‡ãƒ¼ã‚¿ç’°å¢ƒã§ã®çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import asyncio
import json
import os
import sys
from datetime import datetime, timedelta
from typing import Dict, Any

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../'))
sys.path.insert(0, project_root)

from backend.tests.utils.MilestoneTracker import MilestoneTracker
from backend.src.database.config import get_database_connection, connect_db
from backend.src.services.manual_scores_service import ManualScoresService, ManualScoresServiceError


class ManualScoresIntegrationTest:
    """æ‰‹å‹•ã‚¹ã‚³ã‚¢è©•ä¾¡æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def __init__(self):
        """ãƒ†ã‚¹ãƒˆåˆæœŸåŒ–"""
        self.service = ManualScoresService()
        self.test_evaluations = []  # ãƒ†ã‚¹ãƒˆä¸­ã«ä½œæˆã—ãŸã‚¹ã‚³ã‚¢è©•ä¾¡IDã‚’è¨˜éŒ²
        self.tracker = MilestoneTracker()
        print("=== æ‰‹å‹•ã‚¹ã‚³ã‚¢è©•ä¾¡æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
    
    async def setup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.tracker.setOperation("ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
            connected = await connect_db()
            if not connected:
                raise Exception("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå¤±æ•—")
            
            self.tracker.mark("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
            raise
    
    async def test_create_score_evaluation(self) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆ1: ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆ"""
        self.tracker.setOperation("ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆãƒ†ã‚¹ãƒˆ")
        
        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
            test_data = {
                'stock_code': '9984',
                'stock_name': 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—',
                'score': 'A+',
                'logic_type': 'logic_b',
                'scan_result_id': f'scan-result-{datetime.now().strftime("%Y%m%d%H%M%S")}',
                'evaluation_reason': 'é»’å­—è»¢æ›å¾Œã®å¼·ã„ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã¨æŠ€è¡“é©æ–°ã¸ã®æ³¨åŠ›ã€‚AIãƒ“ã‚¸ãƒã‚¹ã®æ‹¡å¤§ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚',
                'confidence_level': 'high',
                'price_at_evaluation': 5840.0,
                'ai_score_before': 'B',
                'follow_up_required': True,
                'follow_up_date': datetime.now() + timedelta(days=30),
                'tags': ['AIéŠ˜æŸ„', 'é»’å­—è»¢æ›', 'ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ '],
                'is_learning_case': True
            }
            
            self.tracker.mark("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
            
            # ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆå®Ÿè¡Œ
            result = await self.service.create_score_evaluation(test_data)
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "ä½œæˆã«å¤±æ•—"
            assert 'score_id' in result, "score_idãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            assert result['evaluation']['stock_code'] == test_data['stock_code'], "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ãªã„"
            assert result['evaluation']['score'] == test_data['score'], "ã‚¹ã‚³ã‚¢ãŒä¸€è‡´ã—ãªã„"
            assert result['evaluation']['logic_type'] == test_data['logic_type'], "ãƒ­ã‚¸ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã—ãªã„"
            
            # ãƒ†ã‚¹ãƒˆç”¨ã«è¨˜éŒ²
            self.test_evaluations.append(result['score_id'])
            
            self.tracker.mark("ä½œæˆçµæœæ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ1: ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆ - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ1: ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆ - å¤±æ•—: {e}")
            raise
    
    async def test_get_score_evaluation(self, stock_code: str) -> Dict[str, Any]:
        """ãƒ†ã‚¹ãƒˆ2: ã‚¹ã‚³ã‚¢è©•ä¾¡å–å¾—"""
        self.tracker.setOperation("ã‚¹ã‚³ã‚¢è©•ä¾¡å–å¾—ãƒ†ã‚¹ãƒˆ")
        
        try:
            # ã‚¹ã‚³ã‚¢è©•ä¾¡å–å¾—å®Ÿè¡Œ
            result = await self.service.get_score_evaluation(stock_code, 'logic_b')
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "å–å¾—ã«å¤±æ•—"
            assert result['evaluation'] is not None, "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã•ã‚Œã¦ã„ãªã„"
            
            evaluation = result['evaluation']
            assert evaluation['stock_code'] == stock_code, "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ãªã„"
            assert evaluation['logic_type'] == 'logic_b', "ãƒ­ã‚¸ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã—ãªã„"
            assert 'score_change_history' in evaluation, "ã‚¹ã‚³ã‚¢å¤‰æ›´å±¥æ­´ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'tags' in evaluation, "ã‚¿ã‚°ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            
            self.tracker.mark("å–å¾—çµæœæ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ2: ã‚¹ã‚³ã‚¢è©•ä¾¡å–å¾— - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ2: ã‚¹ã‚³ã‚¢è©•ä¾¡å–å¾— - å¤±æ•—: {e}")
            raise
    
    async def test_update_score_evaluation(self, score_id: str):
        """ãƒ†ã‚¹ãƒˆ3: ã‚¹ã‚³ã‚¢è©•ä¾¡æ›´æ–°"""
        self.tracker.setOperation("ã‚¹ã‚³ã‚¢è©•ä¾¡æ›´æ–°ãƒ†ã‚¹ãƒˆ")
        
        try:
            # æ›´æ–°ãƒ‡ãƒ¼ã‚¿
            update_data = {
                'score': 'S',
                'evaluation_reason': 'æœŸå¾…ã‚’ä¸Šå›ã‚‹æ¥­ç¸¾ç™ºè¡¨ã«ã‚ˆã‚Šæ ¼ä¸Šã’ã€‚é©æ–°çš„ãªAIæŠ€è¡“ã®å•†ç”¨åŒ–ãŒé€²å±•ã€‚',
                'confidence_level': 'high',
                'ai_score_after': 'A+',
                'performance_validation': {
                    'actual_performance_1w': 15.2,
                    'expected_performance_1w': 8.5,
                    'validation_date': datetime.now().isoformat(),
                    'validation_notes': 'äºˆæƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹'
                },
                'tags': ['AIéŠ˜æŸ„', 'é»’å­—è»¢æ›', 'ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ', 'æ ¼ä¸Šã’'],
                'is_learning_case': True,
                'change_reason': 'æ¥­ç¸¾ç™ºè¡¨ã«ã‚ˆã‚‹ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚µãƒ—ãƒ©ã‚¤ã‚ºã®ãŸã‚æ ¼ä¸Šã’'
            }
            
            # æ›´æ–°å®Ÿè¡Œ
            result = await self.service.update_score_evaluation(score_id, update_data)
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "æ›´æ–°ã«å¤±æ•—"
            assert result['score_id'] == score_id, "score_idãŒä¸€è‡´ã—ãªã„"
            assert 'updated_fields' in result, "updated_fieldsãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            
            # æ›´æ–°å†…å®¹ã®æ¤œè¨¼
            updated_evaluation = result['evaluation']
            assert updated_evaluation['score'] == 'S', "ã‚¹ã‚³ã‚¢ãŒæ›´æ–°ã•ã‚Œã¦ã„ãªã„"
            assert updated_evaluation['ai_score_after'] == 'A+', "AIå¾Œã‚¹ã‚³ã‚¢ãŒæ›´æ–°ã•ã‚Œã¦ã„ãªã„"
            
            # å¤‰æ›´å±¥æ­´ã®ç¢ºèª
            change_history = updated_evaluation['score_change_history']
            assert len(change_history) >= 1, "å¤‰æ›´å±¥æ­´ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãªã„"
            
            self.tracker.mark("æ›´æ–°çµæœæ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ3: ã‚¹ã‚³ã‚¢è©•ä¾¡æ›´æ–° - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ3: ã‚¹ã‚³ã‚¢è©•ä¾¡æ›´æ–° - å¤±æ•—: {e}")
            raise
    
    async def test_search_score_evaluations(self):
        """ãƒ†ã‚¹ãƒˆ4: ã‚¹ã‚³ã‚¢è©•ä¾¡æ¤œç´¢"""
        self.tracker.setOperation("ã‚¹ã‚³ã‚¢è©•ä¾¡æ¤œç´¢ãƒ†ã‚¹ãƒˆ")
        
        try:
            # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            search_params = {
                'logic_type': 'logic_b',
                'confidence_level': 'high',
                'is_learning_case': True,
                'page': 1,
                'limit': 10
            }
            
            # æ¤œç´¢å®Ÿè¡Œ
            result = await self.service.search_score_evaluations(search_params)
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "æ¤œç´¢ã«å¤±æ•—"
            assert 'evaluations' in result, "evaluationsãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            assert 'pagination' in result, "paginationãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            assert result['pagination']['total'] >= 1, "ä½œæˆã—ãŸã‚¹ã‚³ã‚¢è©•ä¾¡ãŒæ¤œç´¢ã•ã‚Œãªã„"
            
            # è©³ç´°æ¤œè¨¼
            found_evaluation = None
            for evaluation in result['evaluations']:
                if evaluation['stock_code'] == '9984':
                    found_evaluation = evaluation
                    break
            
            assert found_evaluation is not None, "ä½œæˆã—ãŸã‚¹ã‚³ã‚¢è©•ä¾¡ãŒè¦‹ã¤ã‹ã‚‰ãªã„"
            assert found_evaluation['logic_type'] == 'logic_b', "ãƒ­ã‚¸ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ãŒä¸€è‡´ã—ãªã„"
            assert found_evaluation['is_learning_case'] == True, "å­¦ç¿’äº‹ä¾‹ãƒ•ãƒ©ã‚°ãŒä¸€è‡´ã—ãªã„"
            
            self.tracker.mark("æ¤œç´¢çµæœæ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ4: ã‚¹ã‚³ã‚¢è©•ä¾¡æ¤œç´¢ - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ4: ã‚¹ã‚³ã‚¢è©•ä¾¡æ¤œç´¢ - å¤±æ•—: {e}")
            raise
    
    async def test_get_score_history(self, stock_code: str):
        """ãƒ†ã‚¹ãƒˆ5: ã‚¹ã‚³ã‚¢è©•ä¾¡å±¥æ­´å–å¾—"""
        self.tracker.setOperation("ã‚¹ã‚³ã‚¢è©•ä¾¡å±¥æ­´å–å¾—ãƒ†ã‚¹ãƒˆ")
        
        try:
            # å±¥æ­´å–å¾—å®Ÿè¡Œï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆå½¢å¼ï¼‰
            result = await self.service.get_score_history(stock_code, compact=True)
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "å±¥æ­´å–å¾—ã«å¤±æ•—"
            assert 'history' in result, "historyãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            assert 'summary' in result, "summaryãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            assert len(result['history']) >= 1, "å±¥æ­´ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãªã„"
            
            # ã‚µãƒãƒªãƒ¼æ¤œè¨¼
            summary = result['summary']
            assert 'latest_score' in summary, "æœ€æ–°ã‚¹ã‚³ã‚¢ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'evaluation_count' in summary, "è©•ä¾¡å›æ•°ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'scores_distribution' in summary, "ã‚¹ã‚³ã‚¢åˆ†å¸ƒãŒå«ã¾ã‚Œã¦ã„ãªã„"
            
            self.tracker.mark("å±¥æ­´æ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ5: ã‚¹ã‚³ã‚¢è©•ä¾¡å±¥æ­´å–å¾— - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ5: ã‚¹ã‚³ã‚¢è©•ä¾¡å±¥æ­´å–å¾— - å¤±æ•—: {e}")
            raise
    
    async def test_get_ai_calculation_status(self, stock_code: str):
        """ãƒ†ã‚¹ãƒˆ6: AI ã‚¹ã‚³ã‚¢è¨ˆç®—çŠ¶æ…‹å–å¾—"""
        self.tracker.setOperation("AI ã‚¹ã‚³ã‚¢è¨ˆç®—çŠ¶æ…‹å–å¾—ãƒ†ã‚¹ãƒˆ")
        
        try:
            # AIè¨ˆç®—çŠ¶æ…‹å–å¾—å®Ÿè¡Œ
            result = await self.service.get_ai_calculation_status(stock_code)
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "AIè¨ˆç®—çŠ¶æ…‹å–å¾—ã«å¤±æ•—"
            assert 'status' in result, "statusãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            
            status = result['status']
            assert 'is_calculating' in status, "is_calculatingãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'stock_code' in status, "stock_codeãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert status['stock_code'] == stock_code, "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ãªã„"
            
            self.tracker.mark("AIè¨ˆç®—çŠ¶æ…‹æ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ6: AI ã‚¹ã‚³ã‚¢è¨ˆç®—çŠ¶æ…‹å–å¾— - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ6: AI ã‚¹ã‚³ã‚¢è¨ˆç®—çŠ¶æ…‹å–å¾— - å¤±æ•—: {e}")
            raise
    
    async def test_get_evaluation_statistics(self):
        """ãƒ†ã‚¹ãƒˆ7: ã‚¹ã‚³ã‚¢è©•ä¾¡çµ±è¨ˆå–å¾—"""
        self.tracker.setOperation("ã‚¹ã‚³ã‚¢è©•ä¾¡çµ±è¨ˆå–å¾—ãƒ†ã‚¹ãƒˆ")
        
        try:
            # çµ±è¨ˆå–å¾—å®Ÿè¡Œ
            result = await self.service.get_evaluation_statistics()
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "çµ±è¨ˆå–å¾—ã«å¤±æ•—"
            assert 'statistics' in result, "statisticsãŒè¿”ã•ã‚Œã¦ã„ãªã„"
            
            stats = result['statistics']
            assert 'total_evaluations' in stats, "ç·è©•ä¾¡ä»¶æ•°ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'score_distribution' in stats, "ã‚¹ã‚³ã‚¢åˆ†å¸ƒãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'confidence_distribution' in stats, "ç¢ºä¿¡åº¦åˆ†å¸ƒãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'logic_type_distribution' in stats, "ãƒ­ã‚¸ãƒƒã‚¯åˆ¥åˆ†å¸ƒãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'quality_metrics' in stats, "å“è³ªæŒ‡æ¨™ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            
            assert stats['total_evaluations'] >= 1, "ä½œæˆã—ãŸã‚¹ã‚³ã‚¢è©•ä¾¡ãŒã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ãªã„"
            
            # å“è³ªæŒ‡æ¨™ã®ç¢ºèª
            quality_metrics = stats['quality_metrics']
            assert 'high_confidence_ratio' in quality_metrics, "é«˜ç¢ºä¿¡åº¦ç‡ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            assert 'learning_cases_ratio' in quality_metrics, "å­¦ç¿’äº‹ä¾‹ç‡ãŒå«ã¾ã‚Œã¦ã„ãªã„"
            
            self.tracker.mark("çµ±è¨ˆæ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ7: ã‚¹ã‚³ã‚¢è©•ä¾¡çµ±è¨ˆå–å¾— - æˆåŠŸ")
            return result
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ7: ã‚¹ã‚³ã‚¢è©•ä¾¡çµ±è¨ˆå–å¾— - å¤±æ•—: {e}")
            raise
    
    async def test_multiple_evaluations_and_superseding(self):
        """ãƒ†ã‚¹ãƒˆ8: è¤‡æ•°è©•ä¾¡ã¨ç½®æ›ãƒ†ã‚¹ãƒˆ"""
        self.tracker.setOperation("è¤‡æ•°è©•ä¾¡ã¨ç½®æ›ãƒ†ã‚¹ãƒˆ")
        
        try:
            # åŒä¸€éŠ˜æŸ„ãƒ»åŒä¸€ãƒ­ã‚¸ãƒƒã‚¯ã§2ã¤ç›®ã®è©•ä¾¡ã‚’ä½œæˆ
            second_evaluation_data = {
                'stock_code': '9984',
                'stock_name': 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—',
                'score': 'B',
                'logic_type': 'logic_b',
                'evaluation_reason': 'æ–°ã—ã„è©•ä¾¡ã«ã‚ˆã‚‹ç½®æ›ãƒ†ã‚¹ãƒˆ',
                'confidence_level': 'medium',
                'price_at_evaluation': 5920.0,
                'change_reason': 'è©•ä¾¡åŸºæº–ã®è¦‹ç›´ã—ã«ã‚ˆã‚‹å†è©•ä¾¡'
            }
            
            # 2ã¤ç›®ã®è©•ä¾¡ä½œæˆ
            result = await self.service.create_score_evaluation(second_evaluation_data)
            
            # çµæœæ¤œè¨¼
            assert result['success'] == True, "2ã¤ç›®ã®è©•ä¾¡ä½œæˆã«å¤±æ•—"
            second_score_id = result['score_id']
            self.test_evaluations.append(second_score_id)
            
            # æœ€æ–°ã®è©•ä¾¡ã‚’å–å¾—ã—ã¦ã€æ–°ã—ã„è©•ä¾¡ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            latest_result = await self.service.get_score_evaluation('9984', 'logic_b')
            assert latest_result['evaluation']['id'] == second_score_id, "æ–°ã—ã„è©•ä¾¡ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã£ã¦ã„ãªã„"
            assert latest_result['evaluation']['score'] == 'B', "æ–°ã—ã„ã‚¹ã‚³ã‚¢ãŒåæ˜ ã•ã‚Œã¦ã„ãªã„"
            
            self.tracker.mark("ç½®æ›å‹•ä½œæ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ8: è¤‡æ•°è©•ä¾¡ã¨ç½®æ›ãƒ†ã‚¹ãƒˆ - æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ8: è¤‡æ•°è©•ä¾¡ã¨ç½®æ›ãƒ†ã‚¹ãƒˆ - å¤±æ•—: {e}")
            raise
    
    async def test_validation_errors(self):
        """ãƒ†ã‚¹ãƒˆ9: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        self.tracker.setOperation("ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ")
        
        try:
            # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆã‚’è©¦è¡Œ
            invalid_data = {
                'stock_code': '999',  # ä¸æ­£ãªéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
                'stock_name': '',     # ç©ºã®éŠ˜æŸ„å
                'score': 'Z',         # ä¸æ­£ãªã‚¹ã‚³ã‚¢
                'logic_type': 'invalid_logic',  # ä¸æ­£ãªãƒ­ã‚¸ãƒƒã‚¯ã‚¿ã‚¤ãƒ—
                'evaluation_reason': '',  # ç©ºã®è©•ä¾¡ç†ç”±
                'confidence_level': 'invalid',  # ä¸æ­£ãªç¢ºä¿¡åº¦
                'price_at_evaluation': -100.0   # è² ã®ä¾¡æ ¼
            }
            
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            try:
                await self.service.create_score_evaluation(invalid_data)
                assert False, "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã‹ã£ãŸ"
            except ManualScoresServiceError as e:
                assert e.code == "VALIDATION_ERROR", f"æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã¨ç•°ãªã‚‹: {e.code}"
            
            # æ›´æ–°æ™‚ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ã‚‚ãƒ†ã‚¹ãƒˆ
            try:
                await self.service.update_score_evaluation("invalid-id", {
                    'score': 'Z',  # ä¸æ­£ãªã‚¹ã‚³ã‚¢
                    # change_reason ãŒå¿…é ˆã ãŒå«ã¾ã‚Œã¦ã„ãªã„
                })
                assert False, "æ›´æ–°æ™‚ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã‹ã£ãŸ"
            except ManualScoresServiceError as e:
                assert e.code in ["VALIDATION_ERROR", "INVALID_ID"], f"æœŸå¾…ã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã¨ç•°ãªã‚‹: {e.code}"
            
            self.tracker.mark("ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼æ¤œè¨¼å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆ9: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ - æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆ9: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ - å¤±æ•—: {e}")
            raise
    
    async def cleanup_test_data(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.tracker.setOperation("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        
        try:
            # ä½œæˆã—ãŸã‚¹ã‚³ã‚¢è©•ä¾¡ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çŠ¶æ…‹ã«å¤‰æ›´
            for score_id in self.test_evaluations:
                try:
                    await self.service.update_score_evaluation(score_id, {
                        'status': 'archived',
                        'change_reason': 'ãƒ†ã‚¹ãƒˆçµ‚äº†ã«ã‚ˆã‚‹ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–'
                    })
                    print(f"ã‚¹ã‚³ã‚¢è©•ä¾¡ {score_id} ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ã¾ã—ãŸ")
                except Exception as e:
                    print(f"ã‚¹ã‚³ã‚¢è©•ä¾¡ {score_id} ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã§ã‚¨ãƒ©ãƒ¼: {e}")
            
            self.tracker.mark("ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            print("âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã§ã‚¨ãƒ©ãƒ¼: {e}")
    
    async def run_all_tests(self):
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        try:
            # ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            await self.setup_test_environment()
            
            # ãƒ†ã‚¹ãƒˆ1: ã‚¹ã‚³ã‚¢è©•ä¾¡ä½œæˆ
            create_result = await self.test_create_score_evaluation()
            score_id = create_result['score_id']
            
            # ãƒ†ã‚¹ãƒˆ2: ã‚¹ã‚³ã‚¢è©•ä¾¡å–å¾—
            await self.test_get_score_evaluation('9984')
            
            # ãƒ†ã‚¹ãƒˆ3: ã‚¹ã‚³ã‚¢è©•ä¾¡æ›´æ–°
            await self.test_update_score_evaluation(score_id)
            
            # ãƒ†ã‚¹ãƒˆ4: ã‚¹ã‚³ã‚¢è©•ä¾¡æ¤œç´¢
            await self.test_search_score_evaluations()
            
            # ãƒ†ã‚¹ãƒˆ5: ã‚¹ã‚³ã‚¢è©•ä¾¡å±¥æ­´å–å¾—
            await self.test_get_score_history('9984')
            
            # ãƒ†ã‚¹ãƒˆ6: AI ã‚¹ã‚³ã‚¢è¨ˆç®—çŠ¶æ…‹å–å¾—
            await self.test_get_ai_calculation_status('9984')
            
            # ãƒ†ã‚¹ãƒˆ7: ã‚¹ã‚³ã‚¢è©•ä¾¡çµ±è¨ˆå–å¾—
            await self.test_get_evaluation_statistics()
            
            # ãƒ†ã‚¹ãƒˆ8: è¤‡æ•°è©•ä¾¡ã¨ç½®æ›ãƒ†ã‚¹ãƒˆ
            await self.test_multiple_evaluations_and_superseding()
            
            # ãƒ†ã‚¹ãƒˆ9: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
            await self.test_validation_errors()
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await self.cleanup_test_data()
            
            # å…¨ä½“çµæœ
            self.tracker.summary()
            print("\nğŸ‰ æ‰‹å‹•ã‚¹ã‚³ã‚¢è©•ä¾¡æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ - å…¨ã¦æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"\nğŸ’¥ æ‰‹å‹•ã‚¹ã‚³ã‚¢è©•ä¾¡æ©Ÿèƒ½çµ±åˆãƒ†ã‚¹ãƒˆ - å¤±æ•—: {e}")
            self.tracker.summary()
            return False


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ç’°å¢ƒå¤‰æ•°è¨­å®š
    os.environ['DATABASE_URL'] = 'sqlite:///./test_database.db'
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test = ManualScoresIntegrationTest()
    success = await test.run_all_tests()
    
    if success:
        print("\nâœ… å…¨ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        return 0
    else:
        print("\nâŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return 1


if __name__ == '__main__':
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)